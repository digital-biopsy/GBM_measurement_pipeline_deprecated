Progress:   0%|                                                                                                                           | 0/90 [00:00<?, ?it/s]
Training: (loss 0.4773):   1%|▉                                                                                                  | 1/110 [00:01<02:19,  1.28s/it]
tensor(2.2128e-08, device='cuda:0', grad_fn=<MinBackward1>)   tensor(1.0000, device='cuda:0', grad_fn=<MaxBackward1>)
tensor(2.9269e-10, device='cuda:0', grad_fn=<MinBackward1>)   tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)

Training: (loss 0.4734):   3%|██▋                                                                                                | 3/110 [00:02<01:31,  1.17it/s]
tensor(2.2276e-08, device='cuda:0', grad_fn=<MinBackward1>)   tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)
tensor(3.8348e-08, device='cuda:0', grad_fn=<MinBackward1>)   tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)

Training: (loss 0.4692):   5%|█████▍                                                                                             | 6/110 [00:05<01:29,  1.16it/s]
tensor(3.6742e-08, device='cuda:0', grad_fn=<MinBackward1>)   tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)

Training: (loss 0.4659):   7%|███████▏                                                                                           | 8/110 [00:07<01:29,  1.13it/s]
tensor(4.6585e-11, device='cuda:0', grad_fn=<MinBackward1>)   tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)

Training: (loss 0.4613):   9%|████████▉                                                                                         | 10/110 [00:08<01:24,  1.19it/s]
tensor(1.5417e-08, device='cuda:0', grad_fn=<MinBackward1>)   tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)

Training: (loss 0.4582):  11%|██████████▋                                                                                       | 12/110 [00:11<01:47,  1.10s/it]
tensor(1.0616e-08, device='cuda:0', grad_fn=<MinBackward1>)   tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)

Training: (loss 0.4540):  13%|████████████▍                                                                                     | 14/110 [00:13<01:35,  1.01it/s]

Training: (loss 0.4544):  14%|█████████████▎                                                                                    | 15/110 [00:14<01:42,  1.08s/it]
tensor(1.1145e-09, device='cuda:0', grad_fn=<MinBackward1>)   tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)


Training: (loss 0.4483):  17%|████████████████▉                                                                                 | 19/110 [00:19<01:49,  1.20s/it]
tensor(3.3168e-11, device='cuda:0', grad_fn=<MinBackward1>)   tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)

Training: (loss 0.4449):  19%|██████████████████▋                                                                               | 21/110 [00:21<01:29,  1.01s/it]
tensor(6.4124e-15, device='cuda:0', grad_fn=<MinBackward1>)   tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)

Training: (loss 0.4408):  21%|████████████████████▍                                                                             | 23/110 [00:23<01:24,  1.03it/s]
tensor(1.1482e-11, device='cuda:0', grad_fn=<MinBackward1>)   tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)
tensor(7.3760e-13, device='cuda:0', grad_fn=<MinBackward1>)   tensor(1.0000, device='cuda:0', grad_fn=<MaxBackward1>)

Training: (loss 0.4383):  22%|█████████████████████▍                                                                            | 24/110 [00:24<01:25,  1.00it/s]
tensor(2.0583e-12, device='cuda:0', grad_fn=<MinBackward1>)   tensor(1.0000, device='cuda:0', grad_fn=<MaxBackward1>)

Training: (loss 0.4363):  24%|███████████████████████▏                                                                          | 26/110 [00:27<01:49,  1.30s/it]
tensor(1.0987e-09, device='cuda:0', grad_fn=<MinBackward1>)   tensor(1.0000, device='cuda:0', grad_fn=<MaxBackward1>)

Training: (loss 0.4352):  25%|████████████████████████▉                                                                         | 28/110 [00:29<01:33,  1.14s/it]

Training: (loss 0.4326):  27%|██████████████████████████▋                                                                       | 30/110 [00:32<01:41,  1.27s/it]
tensor(1.2610e-14, device='cuda:0', grad_fn=<MinBackward1>)   tensor(1.0000, device='cuda:0', grad_fn=<MaxBackward1>)

Training: (loss 0.4291):  29%|████████████████████████████▌                                                                     | 32/110 [00:34<01:26,  1.12s/it]
tensor(5.5914e-10, device='cuda:0', grad_fn=<MinBackward1>)   tensor(1.0000, device='cuda:0', grad_fn=<MaxBackward1>)
tensor(6.1485e-18, device='cuda:0', grad_fn=<MinBackward1>)   tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)

Training: (loss 0.4235):  31%|██████████████████████████████▎                                                                   | 34/110 [00:35<01:16,  1.00s/it]
tensor(1.4443e-11, device='cuda:0', grad_fn=<MinBackward1>)   tensor(1.0000, device='cuda:0', grad_fn=<MaxBackward1>)

Training: (loss 0.4251):  33%|████████████████████████████████                                                                  | 36/110 [00:37<01:12,  1.02it/s]
Traceback (most recent call last):
  File "main.py", line 144, in <module>
    init_and_train_model(args.verbose)
  File "main.py", line 106, in init_and_train_model
    DeepSeg.train_model()
  File "/root/research/deep-segmentation/segmentation/unet/segmentation.py", line 249, in train_model
    training_losses, validation_losses, lr_rates = trainer.run_trainer()
  File "/root/research/deep-segmentation/segmentation/unet/trainer.py", line 59, in run_trainer
    self._train()
  File "/root/research/deep-segmentation/segmentation/unet/trainer.py", line 89, in _train
    for i, (x, y) in batch_iter:
  File "/usr/local/lib/python3.8/dist-packages/tqdm/std.py", line 1180, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/root/research/deep-segmentation/segmentation/unet/customdatasets3.py", line 56, in __getitem__
    x, y = self.transform(x, y)
  File "/root/research/deep-segmentation/segmentation/unet/transformations.py", line 132, in __call__
    inp, target = t(inp, target)
  File "/root/research/deep-segmentation/segmentation/unet/transformations.py", line 114, in __call__
    if self.target: tar = self.function(tar)
  File "/root/research/deep-segmentation/segmentation/unet/transformations.py", line 34, in create_dense_target
    mask = np.where(tar == value)
  File "<__array_function__ internals>", line 5, in where
KeyboardInterrupt