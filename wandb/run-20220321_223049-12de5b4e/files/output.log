
######################### Loading and Augmenting Images #########################
######################### Start Training #########################
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
Progress:   0%|                                                                                                                           | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)                                                      | 0/182 [00:00<?, ?it/s]
Training: (loss 0.9339):   9%|████████▌                                                                                         | 16/182 [00:01<00:16, 10.32it/s]
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
Traceback (most recent call last):
  File "main.py", line 94, in <module>
    init_and_train_model(args.verbose)
  File "main.py", line 65, in init_and_train_model
    DeepSeg.train_model()
  File "/root/research/deep-segmentation/segmentation/unet/segmentation.py", line 246, in train_model
    training_losses, validation_losses, lr_rates = trainer.run_trainer()
  File "/root/research/deep-segmentation/segmentation/unet/trainer.py", line 59, in run_trainer
    self._train()
  File "/root/research/deep-segmentation/segmentation/unet/trainer.py", line 88, in _train
    for i, (x, y) in batch_iter:
  File "/usr/local/lib/python3.8/dist-packages/tqdm/std.py", line 1180, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/root/research/deep-segmentation/segmentation/unet/customdatasets3.py", line 56, in __getitem__
    x, y = self.transform(x, y)
  File "/root/research/deep-segmentation/segmentation/unet/transformations.py", line 132, in __call__
    inp, target = t(inp, target)
  File "/root/research/deep-segmentation/segmentation/unet/transformations.py", line 114, in __call__
    if self.target: tar = self.function(tar)
  File "/root/research/deep-segmentation/segmentation/unet/transformations.py", line 31, in create_dense_target
    classes = np.unique(tar)
  File "<__array_function__ internals>", line 5, in unique
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/arraysetops.py", line 262, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/arraysetops.py", line 323, in _unique1d
    ar.sort()
KeyboardInterrupt
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])
torch.Size([1, 512, 512])