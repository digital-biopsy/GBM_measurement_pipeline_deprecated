
######################### Loading and Augmenting Images #########################
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 32, 512, 512]             320
              ReLU-2         [-1, 32, 512, 512]               0
       BatchNorm2d-3         [-1, 32, 512, 512]              64
            Conv2d-4         [-1, 32, 512, 512]           9,248
              ReLU-5         [-1, 32, 512, 512]               0
       BatchNorm2d-6         [-1, 32, 512, 512]              64
         MaxPool2d-7         [-1, 32, 256, 256]               0
         DownBlock-8  [[-1, 32, 256, 256], [-1, 32, 512, 512]]               0
            Conv2d-9         [-1, 64, 256, 256]          18,496
             ReLU-10         [-1, 64, 256, 256]               0
      BatchNorm2d-11         [-1, 64, 256, 256]             128
           Conv2d-12         [-1, 64, 256, 256]          36,928
             ReLU-13         [-1, 64, 256, 256]               0
      BatchNorm2d-14         [-1, 64, 256, 256]             128
        MaxPool2d-15         [-1, 64, 128, 128]               0
        DownBlock-16  [[-1, 64, 128, 128], [-1, 64, 256, 256]]               0
           Conv2d-17        [-1, 128, 128, 128]          73,856
             ReLU-18        [-1, 128, 128, 128]               0
      BatchNorm2d-19        [-1, 128, 128, 128]             256
           Conv2d-20        [-1, 128, 128, 128]         147,584
             ReLU-21        [-1, 128, 128, 128]               0
      BatchNorm2d-22        [-1, 128, 128, 128]             256
        MaxPool2d-23          [-1, 128, 64, 64]               0
        DownBlock-24  [[-1, 128, 64, 64], [-1, 128, 128, 128]]               0
           Conv2d-25          [-1, 256, 64, 64]         295,168
             ReLU-26          [-1, 256, 64, 64]               0
      BatchNorm2d-27          [-1, 256, 64, 64]             512
           Conv2d-28          [-1, 256, 64, 64]         590,080
             ReLU-29          [-1, 256, 64, 64]               0
      BatchNorm2d-30          [-1, 256, 64, 64]             512
        DownBlock-31  [[-1, 256, 64, 64], [-1, 256, 64, 64]]               0
  ConvTranspose2d-32        [-1, 128, 128, 128]         131,200
             ReLU-33        [-1, 128, 128, 128]               0
      BatchNorm2d-34        [-1, 128, 128, 128]             256
      Concatenate-35        [-1, 256, 128, 128]               0
           Conv2d-36        [-1, 128, 128, 128]         295,040
             ReLU-37        [-1, 128, 128, 128]               0
      BatchNorm2d-38        [-1, 128, 128, 128]             256
           Conv2d-39        [-1, 128, 128, 128]         147,584
             ReLU-40        [-1, 128, 128, 128]               0
      BatchNorm2d-41        [-1, 128, 128, 128]             256
          UpBlock-42        [-1, 128, 128, 128]               0
  ConvTranspose2d-43         [-1, 64, 256, 256]          32,832
             ReLU-44         [-1, 64, 256, 256]               0
      BatchNorm2d-45         [-1, 64, 256, 256]             128
      Concatenate-46        [-1, 128, 256, 256]               0
           Conv2d-47         [-1, 64, 256, 256]          73,792
             ReLU-48         [-1, 64, 256, 256]               0
      BatchNorm2d-49         [-1, 64, 256, 256]             128
           Conv2d-50         [-1, 64, 256, 256]          36,928
             ReLU-51         [-1, 64, 256, 256]               0
      BatchNorm2d-52         [-1, 64, 256, 256]             128
          UpBlock-53         [-1, 64, 256, 256]               0
  ConvTranspose2d-54         [-1, 32, 512, 512]           8,224
             ReLU-55         [-1, 32, 512, 512]               0
      BatchNorm2d-56         [-1, 32, 512, 512]              64
      Concatenate-57         [-1, 64, 512, 512]               0
           Conv2d-58         [-1, 32, 512, 512]          18,464
             ReLU-59         [-1, 32, 512, 512]               0
      BatchNorm2d-60         [-1, 32, 512, 512]              64
           Conv2d-61         [-1, 32, 512, 512]           9,248
             ReLU-62         [-1, 32, 512, 512]               0
      BatchNorm2d-63         [-1, 32, 512, 512]              64
          UpBlock-64         [-1, 32, 512, 512]               0
           Conv2d-65          [-1, 1, 512, 512]              33
================================================================
Total params: 1,928,289
Trainable params: 1,928,289
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 1.00
Forward/backward pass size (MB): 184547282.00
Params size (MB): 7.36
Estimated Total Size (MB): 184547290.36
----------------------------------------------------------------
######################### Start Training #########################
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
Progress:   0%|                                                                                              | 0/90 [00:00<?, ?it/s]

Training: (loss 0.4982):  20%|██████████████                                                        | 11/55 [00:03<00:14,  2.96it/s]
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])

Training: (loss 0.4899):  31%|█████████████████████▋                                                | 17/55 [00:05<00:12,  3.00it/s]
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])

Training: (loss 0.4813):  42%|█████████████████████████████▎                                        | 23/55 [00:07<00:10,  2.97it/s]
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])


Training: (loss 0.4689):  62%|███████████████████████████████████████████▎                          | 34/55 [00:11<00:07,  2.92it/s]
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])

Training: (loss 0.4655):  73%|██████████████████████████████████████████████████▉                   | 40/55 [00:13<00:05,  2.84it/s]
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])

Training: (loss 0.4562):  84%|██████████████████████████████████████████████████████████▌           | 46/55 [00:15<00:03,  2.86it/s]
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])

Training: (loss 0.4492):  95%|██████████████████████████████████████████████████████████████████▏   | 52/55 [00:18<00:01,  2.96it/s]
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])

Validation: (loss 0.4659):   7%|████▉                                                                | 1/14 [00:00<00:12,  1.04it/s]
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([9, 1, 512, 512])





Validation: (loss 0.4619):  86%|██████████████████████████████████████████████████████████▎         | 12/14 [00:10<00:01,  1.12it/s]
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
target shape:  torch.Size([16, 512, 512])
out shape:  torch.Size([16, 1, 512, 512])
Traceback (most recent call last):
  File "main.py", line 126, in <module>
    init_and_train_model(args.verbose)
  File "main.py", line 94, in init_and_train_model
    DeepSeg.train_model()
  File "/root/research/deep-segmentation/segmentation/unet/segmentation.py", line 235, in train_model
    training_losses, validation_losses, lr_rates = trainer.run_trainer()
  File "/root/research/deep-segmentation/segmentation/unet/trainer.py", line 58, in run_trainer
    self._train()
  File "/root/research/deep-segmentation/segmentation/unet/trainer.py", line 91, in _train
    out = self.model(input)  # one forward pass
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/research/deep-segmentation/segmentation/unet/unet.py", line 385, in forward
    x = module(before_pool, x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/research/deep-segmentation/segmentation/unet/unet.py", line 281, in forward
    y = self.norm2(y)  # normalization 2
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/batchnorm.py", line 167, in forward
    return F.batch_norm(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py", line 2281, in batch_norm
    return torch.batch_norm(
KeyboardInterrupt