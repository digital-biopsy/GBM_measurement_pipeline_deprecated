[34m[1mwandb[39m[22m: [33mWARNING[39m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
Progress:   0%|                                                                                               | 0/1 [00:00<?, ?it/s]
























Validation: (loss 0.6606):  93%|███████████████████████████████████████████████████████████████▏    | 52/56 [00:10<00:00,  4.95it/s]
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 512, 512]             640
              ReLU-2         [-1, 64, 512, 512]               0
       BatchNorm2d-3         [-1, 64, 512, 512]             128
            Conv2d-4         [-1, 64, 512, 512]          36,928
              ReLU-5         [-1, 64, 512, 512]               0
       BatchNorm2d-6         [-1, 64, 512, 512]             128
         MaxPool2d-7         [-1, 64, 256, 256]               0
         DownBlock-8  [[-1, 64, 256, 256], [-1, 64, 512, 512]]               0
            Conv2d-9        [-1, 128, 256, 256]          73,856
             ReLU-10        [-1, 128, 256, 256]               0
      BatchNorm2d-11        [-1, 128, 256, 256]             256
           Conv2d-12        [-1, 128, 256, 256]         147,584
             ReLU-13        [-1, 128, 256, 256]               0
      BatchNorm2d-14        [-1, 128, 256, 256]             256
        MaxPool2d-15        [-1, 128, 128, 128]               0
        DownBlock-16  [[-1, 128, 128, 128], [-1, 128, 256, 256]]               0
           Conv2d-17        [-1, 256, 128, 128]         295,168
             ReLU-18        [-1, 256, 128, 128]               0
      BatchNorm2d-19        [-1, 256, 128, 128]             512
           Conv2d-20        [-1, 256, 128, 128]         590,080
             ReLU-21        [-1, 256, 128, 128]               0
      BatchNorm2d-22        [-1, 256, 128, 128]             512
        MaxPool2d-23          [-1, 256, 64, 64]               0
        DownBlock-24  [[-1, 256, 64, 64], [-1, 256, 128, 128]]               0
           Conv2d-25          [-1, 512, 64, 64]       1,180,160
             ReLU-26          [-1, 512, 64, 64]               0
      BatchNorm2d-27          [-1, 512, 64, 64]           1,024
           Conv2d-28          [-1, 512, 64, 64]       2,359,808
             ReLU-29          [-1, 512, 64, 64]               0
      BatchNorm2d-30          [-1, 512, 64, 64]           1,024
        DownBlock-31  [[-1, 512, 64, 64], [-1, 512, 64, 64]]               0
  ConvTranspose2d-32        [-1, 256, 128, 128]         524,544
             ReLU-33        [-1, 256, 128, 128]               0
      BatchNorm2d-34        [-1, 256, 128, 128]             512
      Concatenate-35        [-1, 512, 128, 128]               0
           Conv2d-36        [-1, 256, 128, 128]       1,179,904
             ReLU-37        [-1, 256, 128, 128]               0
      BatchNorm2d-38        [-1, 256, 128, 128]             512
           Conv2d-39        [-1, 256, 128, 128]         590,080
             ReLU-40        [-1, 256, 128, 128]               0
      BatchNorm2d-41        [-1, 256, 128, 128]             512
          UpBlock-42        [-1, 256, 128, 128]               0
  ConvTranspose2d-43        [-1, 128, 256, 256]         131,200
             ReLU-44        [-1, 128, 256, 256]               0
      BatchNorm2d-45        [-1, 128, 256, 256]             256
      Concatenate-46        [-1, 256, 256, 256]               0
           Conv2d-47        [-1, 128, 256, 256]         295,040
             ReLU-48        [-1, 128, 256, 256]               0
      BatchNorm2d-49        [-1, 128, 256, 256]             256
           Conv2d-50        [-1, 128, 256, 256]         147,584
             ReLU-51        [-1, 128, 256, 256]               0
      BatchNorm2d-52        [-1, 128, 256, 256]             256
          UpBlock-53        [-1, 128, 256, 256]               0
  ConvTranspose2d-54         [-1, 64, 512, 512]          32,832
             ReLU-55         [-1, 64, 512, 512]               0
      BatchNorm2d-56         [-1, 64, 512, 512]             128
      Concatenate-57        [-1, 128, 512, 512]               0
           Conv2d-58         [-1, 64, 512, 512]          73,792
             ReLU-59         [-1, 64, 512, 512]               0
      BatchNorm2d-60         [-1, 64, 512, 512]             128
           Conv2d-61         [-1, 64, 512, 512]          36,928
             ReLU-62         [-1, 64, 512, 512]               0
      BatchNorm2d-63         [-1, 64, 512, 512]             128
          UpBlock-64         [-1, 64, 512, 512]               0
           Conv2d-65          [-1, 2, 512, 512]             130
          Sigmoid-66          [-1, 2, 512, 512]               0
================================================================
Total params: 7,702,786
Trainable params: 7,702,786
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 1.00
Forward/backward pass size (MB): 738193312.00
Params size (MB): 29.38
Estimated Total Size (MB): 738193342.38
----------------------------------------------------------------
[32m######################### Start Training #########################
[34m[1mwandb[39m[22m: [33mWARNING[39m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
Progress:   0%|                                                                                               | 0/1 [00:00<?, ?it/s]























Validation: (loss 0.5941):  93%|███████████████████████████████████████████████████████████████▏    | 52/56 [00:10<00:00,  4.96it/s]
[34m[1mwandb[39m[22m: [33mWARNING[39m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
Progress:   0%|                                                                                               | 0/1 [00:00<?, ?it/s]
Training:   0%|                                                                                             | 0/224 [00:00<?, ?it/s]
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 512, 512]             640
              ReLU-2         [-1, 64, 512, 512]               0
       BatchNorm2d-3         [-1, 64, 512, 512]             128
            Conv2d-4         [-1, 64, 512, 512]          36,928
              ReLU-5         [-1, 64, 512, 512]               0
       BatchNorm2d-6         [-1, 64, 512, 512]             128
         MaxPool2d-7         [-1, 64, 256, 256]               0
         DownBlock-8  [[-1, 64, 256, 256], [-1, 64, 512, 512]]               0
            Conv2d-9        [-1, 128, 256, 256]          73,856
             ReLU-10        [-1, 128, 256, 256]               0
      BatchNorm2d-11        [-1, 128, 256, 256]             256
           Conv2d-12        [-1, 128, 256, 256]         147,584
             ReLU-13        [-1, 128, 256, 256]               0
      BatchNorm2d-14        [-1, 128, 256, 256]             256
        MaxPool2d-15        [-1, 128, 128, 128]               0
        DownBlock-16  [[-1, 128, 128, 128], [-1, 128, 256, 256]]               0
           Conv2d-17        [-1, 256, 128, 128]         295,168
             ReLU-18        [-1, 256, 128, 128]               0
      BatchNorm2d-19        [-1, 256, 128, 128]             512
           Conv2d-20        [-1, 256, 128, 128]         590,080
             ReLU-21        [-1, 256, 128, 128]               0
      BatchNorm2d-22        [-1, 256, 128, 128]             512
        MaxPool2d-23          [-1, 256, 64, 64]               0
        DownBlock-24  [[-1, 256, 64, 64], [-1, 256, 128, 128]]               0
           Conv2d-25          [-1, 512, 64, 64]       1,180,160
             ReLU-26          [-1, 512, 64, 64]               0
      BatchNorm2d-27          [-1, 512, 64, 64]           1,024
           Conv2d-28          [-1, 512, 64, 64]       2,359,808
             ReLU-29          [-1, 512, 64, 64]               0
      BatchNorm2d-30          [-1, 512, 64, 64]           1,024
        DownBlock-31  [[-1, 512, 64, 64], [-1, 512, 64, 64]]               0
  ConvTranspose2d-32        [-1, 256, 128, 128]         524,544
             ReLU-33        [-1, 256, 128, 128]               0
      BatchNorm2d-34        [-1, 256, 128, 128]             512
      Concatenate-35        [-1, 512, 128, 128]               0
           Conv2d-36        [-1, 256, 128, 128]       1,179,904
             ReLU-37        [-1, 256, 128, 128]               0
      BatchNorm2d-38        [-1, 256, 128, 128]             512
           Conv2d-39        [-1, 256, 128, 128]         590,080
             ReLU-40        [-1, 256, 128, 128]               0
      BatchNorm2d-41        [-1, 256, 128, 128]             512
          UpBlock-42        [-1, 256, 128, 128]               0
  ConvTranspose2d-43        [-1, 128, 256, 256]         131,200
             ReLU-44        [-1, 128, 256, 256]               0
      BatchNorm2d-45        [-1, 128, 256, 256]             256
      Concatenate-46        [-1, 256, 256, 256]               0
           Conv2d-47        [-1, 128, 256, 256]         295,040
             ReLU-48        [-1, 128, 256, 256]               0
      BatchNorm2d-49        [-1, 128, 256, 256]             256
           Conv2d-50        [-1, 128, 256, 256]         147,584
             ReLU-51        [-1, 128, 256, 256]               0
      BatchNorm2d-52        [-1, 128, 256, 256]             256
          UpBlock-53        [-1, 128, 256, 256]               0
  ConvTranspose2d-54         [-1, 64, 512, 512]          32,832
             ReLU-55         [-1, 64, 512, 512]               0
      BatchNorm2d-56         [-1, 64, 512, 512]             128
      Concatenate-57        [-1, 128, 512, 512]               0
           Conv2d-58         [-1, 64, 512, 512]          73,792
             ReLU-59         [-1, 64, 512, 512]               0
      BatchNorm2d-60         [-1, 64, 512, 512]             128
           Conv2d-61         [-1, 64, 512, 512]          36,928
             ReLU-62         [-1, 64, 512, 512]               0
      BatchNorm2d-63         [-1, 64, 512, 512]             128
          UpBlock-64         [-1, 64, 512, 512]               0
           Conv2d-65          [-1, 2, 512, 512]             130
          Sigmoid-66          [-1, 2, 512, 512]               0
================================================================
Total params: 7,702,786
Trainable params: 7,702,786
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 1.00
Forward/backward pass size (MB): 738193312.00
Params size (MB): 29.38
Estimated Total Size (MB): 738193342.38
----------------------------------------------------------------

























Validation: (loss 0.5985):  88%|███████████████████████████████████████████████████████████▌        | 49/56 [00:11<00:01,  4.40it/s]
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 512, 512]             640
              ReLU-2         [-1, 64, 512, 512]               0
       BatchNorm2d-3         [-1, 64, 512, 512]             128
            Conv2d-4         [-1, 64, 512, 512]          36,928
              ReLU-5         [-1, 64, 512, 512]               0
       BatchNorm2d-6         [-1, 64, 512, 512]             128
         MaxPool2d-7         [-1, 64, 256, 256]               0
         DownBlock-8  [[-1, 64, 256, 256], [-1, 64, 512, 512]]               0
            Conv2d-9        [-1, 128, 256, 256]          73,856
             ReLU-10        [-1, 128, 256, 256]               0
      BatchNorm2d-11        [-1, 128, 256, 256]             256
           Conv2d-12        [-1, 128, 256, 256]         147,584
             ReLU-13        [-1, 128, 256, 256]               0
      BatchNorm2d-14        [-1, 128, 256, 256]             256
        MaxPool2d-15        [-1, 128, 128, 128]               0
        DownBlock-16  [[-1, 128, 128, 128], [-1, 128, 256, 256]]               0
           Conv2d-17        [-1, 256, 128, 128]         295,168
             ReLU-18        [-1, 256, 128, 128]               0
      BatchNorm2d-19        [-1, 256, 128, 128]             512
           Conv2d-20        [-1, 256, 128, 128]         590,080
             ReLU-21        [-1, 256, 128, 128]               0
      BatchNorm2d-22        [-1, 256, 128, 128]             512
        MaxPool2d-23          [-1, 256, 64, 64]               0
        DownBlock-24  [[-1, 256, 64, 64], [-1, 256, 128, 128]]               0
           Conv2d-25          [-1, 512, 64, 64]       1,180,160
             ReLU-26          [-1, 512, 64, 64]               0
      BatchNorm2d-27          [-1, 512, 64, 64]           1,024
           Conv2d-28          [-1, 512, 64, 64]       2,359,808
             ReLU-29          [-1, 512, 64, 64]               0
      BatchNorm2d-30          [-1, 512, 64, 64]           1,024
        DownBlock-31  [[-1, 512, 64, 64], [-1, 512, 64, 64]]               0
  ConvTranspose2d-32        [-1, 256, 128, 128]         524,544
             ReLU-33        [-1, 256, 128, 128]               0
      BatchNorm2d-34        [-1, 256, 128, 128]             512
      Concatenate-35        [-1, 512, 128, 128]               0
           Conv2d-36        [-1, 256, 128, 128]       1,179,904
             ReLU-37        [-1, 256, 128, 128]               0
      BatchNorm2d-38        [-1, 256, 128, 128]             512
           Conv2d-39        [-1, 256, 128, 128]         590,080
             ReLU-40        [-1, 256, 128, 128]               0
      BatchNorm2d-41        [-1, 256, 128, 128]             512
          UpBlock-42        [-1, 256, 128, 128]               0
  ConvTranspose2d-43        [-1, 128, 256, 256]         131,200
             ReLU-44        [-1, 128, 256, 256]               0
      BatchNorm2d-45        [-1, 128, 256, 256]             256
      Concatenate-46        [-1, 256, 256, 256]               0
           Conv2d-47        [-1, 128, 256, 256]         295,040
             ReLU-48        [-1, 128, 256, 256]               0
      BatchNorm2d-49        [-1, 128, 256, 256]             256
           Conv2d-50        [-1, 128, 256, 256]         147,584
             ReLU-51        [-1, 128, 256, 256]               0
      BatchNorm2d-52        [-1, 128, 256, 256]             256
          UpBlock-53        [-1, 128, 256, 256]               0
  ConvTranspose2d-54         [-1, 64, 512, 512]          32,832
             ReLU-55         [-1, 64, 512, 512]               0
      BatchNorm2d-56         [-1, 64, 512, 512]             128
      Concatenate-57        [-1, 128, 512, 512]               0
           Conv2d-58         [-1, 64, 512, 512]          73,792
             ReLU-59         [-1, 64, 512, 512]               0
      BatchNorm2d-60         [-1, 64, 512, 512]             128
           Conv2d-61         [-1, 64, 512, 512]          36,928
             ReLU-62         [-1, 64, 512, 512]               0
      BatchNorm2d-63         [-1, 64, 512, 512]             128
          UpBlock-64         [-1, 64, 512, 512]               0
           Conv2d-65          [-1, 2, 512, 512]             130
          Sigmoid-66          [-1, 2, 512, 512]               0
================================================================
Total params: 7,702,786
Trainable params: 7,702,786
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 1.00
Forward/backward pass size (MB): 738193312.00
Params size (MB): 29.38
Estimated Total Size (MB): 738193342.38
----------------------------------------------------------------
[32m######################### Start Training #########################
[34m[1mwandb[39m[22m: [33mWARNING[39m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
Progress:   0%|                                                                                               | 0/1 [00:00<?, ?it/s]
























Validation: (loss 0.6645):  93%|███████████████████████████████████████████████████████████████▏    | 52/56 [00:10<00:00,  4.90it/s]
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 512, 512]             640
              ReLU-2         [-1, 64, 512, 512]               0
       BatchNorm2d-3         [-1, 64, 512, 512]             128
            Conv2d-4         [-1, 64, 512, 512]          36,928
              ReLU-5         [-1, 64, 512, 512]               0
       BatchNorm2d-6         [-1, 64, 512, 512]             128
         MaxPool2d-7         [-1, 64, 256, 256]               0
         DownBlock-8  [[-1, 64, 256, 256], [-1, 64, 512, 512]]               0
            Conv2d-9        [-1, 128, 256, 256]          73,856
             ReLU-10        [-1, 128, 256, 256]               0
      BatchNorm2d-11        [-1, 128, 256, 256]             256
           Conv2d-12        [-1, 128, 256, 256]         147,584
             ReLU-13        [-1, 128, 256, 256]               0
      BatchNorm2d-14        [-1, 128, 256, 256]             256
        MaxPool2d-15        [-1, 128, 128, 128]               0
        DownBlock-16  [[-1, 128, 128, 128], [-1, 128, 256, 256]]               0
           Conv2d-17        [-1, 256, 128, 128]         295,168
             ReLU-18        [-1, 256, 128, 128]               0
      BatchNorm2d-19        [-1, 256, 128, 128]             512
           Conv2d-20        [-1, 256, 128, 128]         590,080
             ReLU-21        [-1, 256, 128, 128]               0
      BatchNorm2d-22        [-1, 256, 128, 128]             512
        MaxPool2d-23          [-1, 256, 64, 64]               0
        DownBlock-24  [[-1, 256, 64, 64], [-1, 256, 128, 128]]               0
           Conv2d-25          [-1, 512, 64, 64]       1,180,160
             ReLU-26          [-1, 512, 64, 64]               0
      BatchNorm2d-27          [-1, 512, 64, 64]           1,024
           Conv2d-28          [-1, 512, 64, 64]       2,359,808
             ReLU-29          [-1, 512, 64, 64]               0
      BatchNorm2d-30          [-1, 512, 64, 64]           1,024
        DownBlock-31  [[-1, 512, 64, 64], [-1, 512, 64, 64]]               0
  ConvTranspose2d-32        [-1, 256, 128, 128]         524,544
             ReLU-33        [-1, 256, 128, 128]               0
      BatchNorm2d-34        [-1, 256, 128, 128]             512
      Concatenate-35        [-1, 512, 128, 128]               0
           Conv2d-36        [-1, 256, 128, 128]       1,179,904
             ReLU-37        [-1, 256, 128, 128]               0
      BatchNorm2d-38        [-1, 256, 128, 128]             512
           Conv2d-39        [-1, 256, 128, 128]         590,080
             ReLU-40        [-1, 256, 128, 128]               0
      BatchNorm2d-41        [-1, 256, 128, 128]             512
          UpBlock-42        [-1, 256, 128, 128]               0
  ConvTranspose2d-43        [-1, 128, 256, 256]         131,200
             ReLU-44        [-1, 128, 256, 256]               0
      BatchNorm2d-45        [-1, 128, 256, 256]             256
      Concatenate-46        [-1, 256, 256, 256]               0
           Conv2d-47        [-1, 128, 256, 256]         295,040
             ReLU-48        [-1, 128, 256, 256]               0
      BatchNorm2d-49        [-1, 128, 256, 256]             256
           Conv2d-50        [-1, 128, 256, 256]         147,584
             ReLU-51        [-1, 128, 256, 256]               0
      BatchNorm2d-52        [-1, 128, 256, 256]             256
          UpBlock-53        [-1, 128, 256, 256]               0
  ConvTranspose2d-54         [-1, 64, 512, 512]          32,832
             ReLU-55         [-1, 64, 512, 512]               0
      BatchNorm2d-56         [-1, 64, 512, 512]             128
      Concatenate-57        [-1, 128, 512, 512]               0
           Conv2d-58         [-1, 64, 512, 512]          73,792
             ReLU-59         [-1, 64, 512, 512]               0
      BatchNorm2d-60         [-1, 64, 512, 512]             128
           Conv2d-61         [-1, 64, 512, 512]          36,928
             ReLU-62         [-1, 64, 512, 512]               0
      BatchNorm2d-63         [-1, 64, 512, 512]             128
          UpBlock-64         [-1, 64, 512, 512]               0
           Conv2d-65          [-1, 2, 512, 512]             130
          Sigmoid-66          [-1, 2, 512, 512]               0
================================================================
Total params: 7,702,786
Trainable params: 7,702,786
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 1.00
Forward/backward pass size (MB): 738193312.00
Params size (MB): 29.38
Estimated Total Size (MB): 738193342.38
----------------------------------------------------------------
[32m######################### Start Training #########################
[34m[1mwandb[39m[22m: [33mWARNING[39m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
Progress:   0%|                                                                                               | 0/1 [00:00<?, ?it/s]























Validation: (loss 0.4694):  89%|████████████████████████████████████████████████████████████▋       | 50/56 [00:10<00:01,  4.42it/s]