
######################### Loading and Augmenting Images #########################
Progress:   0%|                                                                                                                           | 0/40 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)                                                      | 0/912 [00:00<?, ?it/s]
Training: (loss 0.7110):   1%|▉                                                                                                  | 9/912 [00:00<01:22, 10.90it/s]
######################### Start Training #########################
tensor(1.0051, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.9631, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.8841, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.9422, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.8001, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7673, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6384, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7032, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7110, device='cuda:0', grad_fn=<NllLoss2DBackward>)

Training: (loss 0.4101):   3%|███▏                                                                                              | 30/912 [00:02<01:20, 10.92it/s]
tensor(1.0595, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.8930, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(1.0768, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.8653, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5554, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6900, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6277, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.9852, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6756, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6575, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7995, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.8545, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7649, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.9006, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4825, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6517, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7468, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7249, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6338, device='cuda:0', grad_fn=<NllLoss2DBackward>)

Training: (loss 0.6176):   5%|█████▏                                                                                            | 48/912 [00:04<01:21, 10.57it/s]
tensor(0.6439, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7117, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(1.2799, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4310, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6602, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5303, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5638, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5561, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6961, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7044, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5871, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4820, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4655, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6488, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.9757, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6547, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7086, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6176, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5862, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(1.1295, device='cuda:0', grad_fn=<NllLoss2DBackward>)

Training: (loss 0.5754):   7%|███████▏                                                                                          | 67/912 [00:06<01:29,  9.44it/s]
tensor(0.6667, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5401, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7713, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4950, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4670, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3701, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6149, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4981, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4028, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4103, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(1.1124, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5209, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5386, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5591, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4450, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7037, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5754, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(1.0687, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7759, device='cuda:0', grad_fn=<NllLoss2DBackward>)

Training: (loss 0.6113):  10%|█████████▌                                                                                        | 89/912 [00:08<01:20, 10.18it/s]
tensor(0.6067, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6521, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5928, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6068, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7805, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5809, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5055, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5363, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4159, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4585, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5339, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3771, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6817, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7137, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4252, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3768, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.8220, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7474, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6113, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6508, device='cuda:0', grad_fn=<NllLoss2DBackward>)

Training: (loss 0.4441):  12%|███████████▊                                                                                     | 111/912 [00:10<01:17, 10.33it/s]
tensor(0.7427, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4677, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5207, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7210, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5092, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3904, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4832, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.8227, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5559, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5774, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5673, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5112, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4848, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4481, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(1.2491, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5411, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5337, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4612, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(1.0838, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4441, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.8445, device='cuda:0', grad_fn=<NllLoss2DBackward>)

Training: (loss 0.4095):  15%|██████████████▏                                                                                  | 133/912 [00:13<01:18,  9.93it/s]
tensor(0.5368, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5116, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6028, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4623, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4455, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7453, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4600, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.8027, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6909, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7573, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4757, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5270, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4756, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4724, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5176, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6435, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5659, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4307, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4095, device='cuda:0', grad_fn=<NllLoss2DBackward>)

Training: (loss 0.4393):  17%|████████████████▏                                                                                | 152/912 [00:14<01:16,  9.96it/s]
tensor(0.5022, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5442, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4935, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6061, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5439, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6403, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4157, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6255, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3052, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.8359, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6101, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4924, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6571, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5228, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.2929, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3956, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6090, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4393, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3927, device='cuda:0', grad_fn=<NllLoss2DBackward>)

Training: (loss 0.6073):  19%|█████████████████▉                                                                               | 169/912 [00:16<01:14,  9.95it/s]
tensor(0.3339, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4914, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4599, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5517, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4307, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(1.2204, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3476, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4532, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7210, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4816, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5237, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5246, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3697, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5190, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6073, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.2921, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4541, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4896, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7925, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(1.2016, device='cuda:0', grad_fn=<NllLoss2DBackward>)

Training: (loss 0.4285):  21%|████████████████████                                                                             | 189/912 [00:18<01:11, 10.07it/s]
tensor(0.4851, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4899, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4297, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5160, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6287, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7219, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4761, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4320, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4225, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5782, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4819, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4353, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5342, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3384, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4285, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3670, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4297, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4801, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6199, device='cuda:0', grad_fn=<NllLoss2DBackward>)

Training: (loss 1.2540):  23%|██████████████████████▍                                                                          | 211/912 [00:20<01:04, 10.88it/s]
tensor(0.5912, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7838, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4074, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5141, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4338, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3671, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3996, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3423, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5685, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5524, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4285, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4425, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4231, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4566, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4591, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.2863, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(1.2540, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(1.0343, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6227, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4367, device='cuda:0', grad_fn=<NllLoss2DBackward>)

Training: (loss 0.4587):  26%|████████████████████████▊                                                                        | 233/912 [00:23<01:07, 10.05it/s]
tensor(0.3353, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.2742, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3194, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6507, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5412, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(1.2114, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(1.1497, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4090, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4753, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4434, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4633, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5262, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4040, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4908, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5336, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4372, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4587, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4189, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(1.2576, device='cuda:0', grad_fn=<NllLoss2DBackward>)

Training: (loss 0.4959):  28%|███████████████████████████                                                                      | 255/912 [00:25<01:04, 10.16it/s]
tensor(0.5850, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.9064, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(1.1401, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3642, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5107, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4005, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5993, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5732, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4741, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(1.1277, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4301, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5277, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3778, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4427, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(1.1891, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4833, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3859, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3918, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4959, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4321, device='cuda:0', grad_fn=<NllLoss2DBackward>)

Training: (loss 0.4381):  30%|████████████████████████████▊                                                                    | 271/912 [00:26<01:04, 10.01it/s]
tensor(0.5018, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4199, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5868, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5510, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3837, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4148, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4352, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3253, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4068, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5075, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5842, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6580, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4119, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4818, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.8646, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4381, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3980, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6095, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3778, device='cuda:0', grad_fn=<NllLoss2DBackward>)

Training: (loss 0.4714):  32%|██████████████████████████████▊                                                                  | 290/912 [00:28<01:02,  9.94it/s]
tensor(0.3630, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5574, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3686, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.7137, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4491, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5343, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3623, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3263, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3577, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4720, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.2663, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.2511, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3876, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4714, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4215, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3696, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3927, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5555, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.2696, device='cuda:0', grad_fn=<NllLoss2DBackward>)

Training: (loss 0.4164):  34%|█████████████████████████████████▏                                                               | 312/912 [00:31<00:59, 10.02it/s]
tensor(0.3825, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6572, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4790, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5611, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.6485, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4525, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5252, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3888, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5887, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.8126, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3313, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4240, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(1.3297, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4254, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.4314, device='cuda:0', grad_fn=<NllLoss2DBackward>)

Training: (loss 0.3755):  37%|███████████████████████████████████▌                                                             | 334/912 [00:33<00:52, 11.07it/s]
tensor(0.4271, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3504, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3200, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3382, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3559, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3120, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3798, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3440, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(1.3572, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.2441, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3831, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3319, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3784, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3909, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3884, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.2799, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.2644, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3762, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.8356, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.5687, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3755, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3300, device='cuda:0', grad_fn=<NllLoss2DBackward>)
tensor(0.3129, device='cuda:0', grad_fn=<NllLoss2DBackward>)
Traceback (most recent call last):
  File "main.py", line 71, in <module>
    train_model(
  File "main.py", line 57, in train_model
    DeepSeg.train_model()
  File "/root/research/deep-segmentation/segmentation/unet/segmentation.py", line 238, in train_model
    training_losses, validation_losses, lr_rates = trainer.run_trainer()
  File "/root/research/deep-segmentation/segmentation/unet/trainer.py", line 58, in run_trainer
    self._train()
  File "/root/research/deep-segmentation/segmentation/unet/trainer.py", line 88, in _train
    print(loss)
  File "/usr/local/lib/python3.8/dist-packages/torch/_tensor.py", line 203, in __repr__
    return torch._tensor_str._str(self)
  File "/usr/local/lib/python3.8/dist-packages/torch/_tensor_str.py", line 406, in _str
    return _str_intern(self)
  File "/usr/local/lib/python3.8/dist-packages/torch/_tensor_str.py", line 381, in _str_intern
    tensor_str = _tensor_str(self, indent)
  File "/usr/local/lib/python3.8/dist-packages/torch/_tensor_str.py", line 242, in _tensor_str
    formatter = _Formatter(get_summarized_data(self) if summarize else self)
  File "/usr/local/lib/python3.8/dist-packages/torch/_tensor_str.py", line 120, in __init__
    if nonzero_finite_max / nonzero_finite_min > 1000.\
KeyboardInterrupt