
######################### Loading and Augmenting Images #########################
######################### Start Training #########################
Progress:   0%|                                                                                                                           | 0/90 [00:00<?, ?it/s]
Training:   0%|                                                                                                                           | 0/55 [00:00<?, ?it/s]
torch.Size([16, 2, 512, 512])
torch.Size([16, 512, 512])
torch.Size([16, 2, 512, 512])
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)                                                       | 0/55 [00:00<?, ?it/s]

Training: (loss 0.7478):   5%|█████▍                                                                                              | 3/55 [00:04<01:15,  1.45s/it]
torch.Size([16, 2, 512, 512])

Training: (loss 0.7427):   7%|███████▎                                                                                            | 4/55 [00:06<01:19,  1.55s/it]
torch.Size([16, 2, 512, 512])

Training: (loss 0.7158):  11%|██████████▉                                                                                         | 6/55 [00:09<01:16,  1.57s/it]
torch.Size([16, 2, 512, 512])
torch.Size([16, 512, 512])
torch.Size([16, 2, 512, 512])
torch.Size([16, 512, 512])
torch.Size([16, 2, 512, 512])


Training: (loss 0.7419):  15%|██████████████▌                                                                                     | 8/55 [00:12<01:10,  1.49s/it]
torch.Size([16, 2, 512, 512])

Training: (loss 0.7219):  18%|██████████████████                                                                                 | 10/55 [00:14<01:05,  1.45s/it]
torch.Size([16, 2, 512, 512])
torch.Size([16, 512, 512])
torch.Size([16, 2, 512, 512])
torch.Size([16, 512, 512])
torch.Size([16, 2, 512, 512])

Training: (loss 0.6959):  20%|███████████████████▊                                                                               | 11/55 [00:16<01:07,  1.53s/it]
torch.Size([16, 2, 512, 512])


Training: (loss 0.6824):  25%|█████████████████████████▏                                                                         | 14/55 [00:20<00:59,  1.46s/it]
torch.Size([16, 2, 512, 512])
torch.Size([16, 512, 512])
torch.Size([16, 2, 512, 512])

Training: (loss 0.6702):  27%|██████████████████████████▉                                                                        | 15/55 [00:22<00:58,  1.47s/it]
torch.Size([16, 2, 512, 512])

Training: (loss 0.6867):  31%|██████████████████████████████▌                                                                    | 17/55 [00:25<00:56,  1.48s/it]
torch.Size([16, 2, 512, 512])

Training: (loss 0.6403):  33%|████████████████████████████████▍                                                                  | 18/55 [00:26<00:52,  1.42s/it]
torch.Size([16, 2, 512, 512])
torch.Size([16, 512, 512])
torch.Size([16, 2, 512, 512])

Training: (loss 0.6606):  35%|██████████████████████████████████▏                                                                | 19/55 [00:28<00:53,  1.48s/it]
torch.Size([16, 2, 512, 512])

Training: (loss 0.6739):  38%|█████████████████████████████████████▊                                                             | 21/55 [00:31<00:50,  1.50s/it]
torch.Size([16, 2, 512, 512])
torch.Size([16, 512, 512])
torch.Size([16, 2, 512, 512])

Training: (loss 0.6815):  40%|███████████████████████████████████████▌                                                           | 22/55 [00:32<00:48,  1.47s/it]
torch.Size([16, 2, 512, 512])

Training: (loss 0.6562):  44%|███████████████████████████████████████████▏                                                       | 24/55 [00:35<00:44,  1.42s/it]
torch.Size([16, 2, 512, 512])
torch.Size([16, 512, 512])
torch.Size([16, 2, 512, 512])

Training: (loss 0.6033):  45%|█████████████████████████████████████████████                                                      | 25/55 [00:36<00:41,  1.39s/it]
torch.Size([16, 2, 512, 512])
torch.Size([16, 512, 512])
torch.Size([16, 2, 512, 512])
torch.Size([16, 512, 512])
torch.Size([16, 2, 512, 512])

Training: (loss 0.6389):  49%|████████████████████████████████████████████████▌                                                  | 27/55 [00:39<00:38,  1.37s/it]
torch.Size([16, 2, 512, 512])

Training: (loss 0.6118):  51%|██████████████████████████████████████████████████▍                                                | 28/55 [00:41<00:38,  1.43s/it]
torch.Size([16, 2, 512, 512])
torch.Size([16, 512, 512])
torch.Size([16, 2, 512, 512])

Training: (loss 0.5688):  53%|████████████████████████████████████████████████████▏                                              | 29/55 [00:42<00:37,  1.45s/it]
torch.Size([16, 2, 512, 512])
Traceback (most recent call last):
  File "main.py", line 98, in <module>
    init_and_train_model(args.verbose)
  File "main.py", line 69, in init_and_train_model
    DeepSeg.train_model()
  File "/root/research/deep-segmentation/segmentation/unet/segmentation.py", line 247, in train_model
    training_losses, validation_losses, lr_rates = trainer.run_trainer()
  File "/root/research/deep-segmentation/segmentation/unet/trainer.py", line 59, in run_trainer
    self._train()
  File "/root/research/deep-segmentation/segmentation/unet/trainer.py", line 89, in _train
    for i, (x, y) in batch_iter:
  File "/usr/local/lib/python3.8/dist-packages/tqdm/std.py", line 1180, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/root/research/deep-segmentation/segmentation/unet/customdatasets3.py", line 56, in __getitem__
    x, y = self.transform(x, y)
  File "/root/research/deep-segmentation/segmentation/unet/transformations.py", line 132, in __call__
    inp, target = t(inp, target)
  File "/root/research/deep-segmentation/segmentation/unet/transformations.py", line 114, in __call__
    if self.target: tar = self.function(tar)
  File "/root/research/deep-segmentation/segmentation/unet/transformations.py", line 31, in create_dense_target
    classes = np.unique(tar)
  File "<__array_function__ internals>", line 5, in unique
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/arraysetops.py", line 262, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/arraysetops.py", line 323, in _unique1d
    ar.sort()
KeyboardInterrupt