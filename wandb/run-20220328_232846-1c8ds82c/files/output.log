
######################### Loading and Augmenting Images #########################
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Progress:   0%|                                                                                              | 0/90 [00:00<?, ?it/s]
Training: (loss 0.8958):   4%|██▌                                                                    | 2/55 [00:00<00:22,  2.32it/s]
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 32, 512, 512]             320
              ReLU-2         [-1, 32, 512, 512]               0
       BatchNorm2d-3         [-1, 32, 512, 512]              64
            Conv2d-4         [-1, 32, 512, 512]           9,248
              ReLU-5         [-1, 32, 512, 512]               0
       BatchNorm2d-6         [-1, 32, 512, 512]              64
         MaxPool2d-7         [-1, 32, 256, 256]               0
         DownBlock-8  [[-1, 32, 256, 256], [-1, 32, 512, 512]]               0
            Conv2d-9         [-1, 64, 256, 256]          18,496
             ReLU-10         [-1, 64, 256, 256]               0
      BatchNorm2d-11         [-1, 64, 256, 256]             128
           Conv2d-12         [-1, 64, 256, 256]          36,928
             ReLU-13         [-1, 64, 256, 256]               0
      BatchNorm2d-14         [-1, 64, 256, 256]             128
        MaxPool2d-15         [-1, 64, 128, 128]               0
        DownBlock-16  [[-1, 64, 128, 128], [-1, 64, 256, 256]]               0
           Conv2d-17        [-1, 128, 128, 128]          73,856
             ReLU-18        [-1, 128, 128, 128]               0
      BatchNorm2d-19        [-1, 128, 128, 128]             256
           Conv2d-20        [-1, 128, 128, 128]         147,584
             ReLU-21        [-1, 128, 128, 128]               0
      BatchNorm2d-22        [-1, 128, 128, 128]             256
        MaxPool2d-23          [-1, 128, 64, 64]               0
        DownBlock-24  [[-1, 128, 64, 64], [-1, 128, 128, 128]]               0
           Conv2d-25          [-1, 256, 64, 64]         295,168
             ReLU-26          [-1, 256, 64, 64]               0
      BatchNorm2d-27          [-1, 256, 64, 64]             512
           Conv2d-28          [-1, 256, 64, 64]         590,080
             ReLU-29          [-1, 256, 64, 64]               0
      BatchNorm2d-30          [-1, 256, 64, 64]             512
        DownBlock-31  [[-1, 256, 64, 64], [-1, 256, 64, 64]]               0
  ConvTranspose2d-32        [-1, 128, 128, 128]         131,200
             ReLU-33        [-1, 128, 128, 128]               0
      BatchNorm2d-34        [-1, 128, 128, 128]             256
      Concatenate-35        [-1, 256, 128, 128]               0
           Conv2d-36        [-1, 128, 128, 128]         295,040
             ReLU-37        [-1, 128, 128, 128]               0
      BatchNorm2d-38        [-1, 128, 128, 128]             256
           Conv2d-39        [-1, 128, 128, 128]         147,584
             ReLU-40        [-1, 128, 128, 128]               0
      BatchNorm2d-41        [-1, 128, 128, 128]             256
          UpBlock-42        [-1, 128, 128, 128]               0
  ConvTranspose2d-43         [-1, 64, 256, 256]          32,832
             ReLU-44         [-1, 64, 256, 256]               0
      BatchNorm2d-45         [-1, 64, 256, 256]             128
      Concatenate-46        [-1, 128, 256, 256]               0
           Conv2d-47         [-1, 64, 256, 256]          73,792
             ReLU-48         [-1, 64, 256, 256]               0
      BatchNorm2d-49         [-1, 64, 256, 256]             128
           Conv2d-50         [-1, 64, 256, 256]          36,928
             ReLU-51         [-1, 64, 256, 256]               0
      BatchNorm2d-52         [-1, 64, 256, 256]             128
          UpBlock-53         [-1, 64, 256, 256]               0
  ConvTranspose2d-54         [-1, 32, 512, 512]           8,224
             ReLU-55         [-1, 32, 512, 512]               0
      BatchNorm2d-56         [-1, 32, 512, 512]              64
      Concatenate-57         [-1, 64, 512, 512]               0
           Conv2d-58         [-1, 32, 512, 512]          18,464
             ReLU-59         [-1, 32, 512, 512]               0
      BatchNorm2d-60         [-1, 32, 512, 512]              64
           Conv2d-61         [-1, 32, 512, 512]           9,248
             ReLU-62         [-1, 32, 512, 512]               0
      BatchNorm2d-63         [-1, 32, 512, 512]              64
          UpBlock-64         [-1, 32, 512, 512]               0
           Conv2d-65          [-1, 2, 512, 512]              66
================================================================
Total params: 1,928,322
Trainable params: 1,928,322
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 1.00
Forward/backward pass size (MB): 184547280.00
Params size (MB): 7.36
Estimated Total Size (MB): 184547288.36
----------------------------------------------------------------
######################### Start Training #########################
Loss 0 tensor(0.5034, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4961, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5035, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4942, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5045, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.8062):  15%|██████████▎                                                            | 8/55 [00:02<00:16,  2.86it/s]
Loss 0 tensor(0.5071, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4934, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5073, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4913, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5087, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4903, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5115, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4889, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5145, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.7269):  25%|█████████████████▊                                                    | 14/55 [00:05<00:14,  2.91it/s]
Loss 0 tensor(0.5149, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4884, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5145, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4879, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5148, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4858, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5128, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4823, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5129, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4844, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5210, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.7264):  33%|██████████████████████▉                                               | 18/55 [00:06<00:19,  1.94it/s]
Loss 0 tensor(0.5207, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4794, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5221, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4822, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5210, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4789, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5209, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.6764):  40%|████████████████████████████                                          | 22/55 [00:08<00:15,  2.08it/s]
Loss 0 tensor(0.5199, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4756, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5167, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4746, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5257, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4735, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5290, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.6544):  51%|███████████████████████████████████▋                                  | 28/55 [00:11<00:09,  2.79it/s]
Loss 0 tensor(0.5232, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4729, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5295, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4715, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5285, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4722, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5297, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4689, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5331, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4667, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5282, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.6636):  62%|███████████████████████████████████████████▎                          | 34/55 [00:13<00:07,  2.90it/s]
Loss 0 tensor(0.5305, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4629, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5286, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4631, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5263, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4606, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5303, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4597, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5350, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4586, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5305, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4582, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5359, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4606, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5281, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4501, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5306, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.6432):  67%|███████████████████████████████████████████████                       | 37/55 [00:14<00:08,  2.13it/s]
Loss 0 tensor(0.5332, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4551, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5355, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4501, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5366, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4511, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5372, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4528, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5379, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.6571):  76%|█████████████████████████████████████████████████████▍                | 42/55 [00:17<00:05,  2.33it/s]
Loss 0 tensor(0.5397, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4522, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5420, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4502, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5358, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4477, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5409, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4488, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5436, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.6314):  87%|█████████████████████████████████████████████████████████████         | 48/55 [00:19<00:02,  2.84it/s]
Loss 0 tensor(0.5383, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4456, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5434, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4453, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5415, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4437, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5437, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4405, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5501, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4423, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5417, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5825):  95%|██████████████████████████████████████████████████████████████████▏   | 52/55 [00:20<00:01,  2.91it/s]
Loss 0 tensor(0.5465, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4403, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5412, device='cuda:0', grad_fn=<RsubBackward1>)





Validation: (loss 0.6520):  79%|█████████████████████████████████████████████████████▍              | 11/14 [00:09<00:02,  1.24it/s]
Loss 0 tensor(0.5409, device='cuda:0', grad_fn=<RsubBackward1>)

Training:   0%|                                                                                              | 0/55 [00:00<?, ?it/s]
Loss 0 tensor(0.5484, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4416, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5456, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4345, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5496, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4361, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5527, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4337, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5566, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4350, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5479, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5476):  11%|███████▋                                                               | 6/55 [00:02<00:16,  2.94it/s]
Loss 0 tensor(0.5523, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4313, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5510, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4274, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5545, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4279, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5488, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4289, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5581, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5852):  20%|██████████████                                                        | 11/55 [00:04<00:21,  2.09it/s]
Loss 0 tensor(0.5533, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4252, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5539, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4285, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5536, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4244, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5554, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4240, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5580, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5576):  29%|████████████████████▎                                                 | 16/55 [00:06<00:15,  2.52it/s]
Loss 0 tensor(0.5579, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4276, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5612, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4267, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5568, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4219, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5609, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4190, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5579, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.5322):  49%|██████████████████████████████████▎                                   | 27/55 [00:09<00:09,  2.92it/s]
Loss 0 tensor(0.5568, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4158, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5590, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4206, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5636, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4150, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5627, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4112, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5628, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4181, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5629, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5072):  56%|███████████████████████████████████████▍                              | 31/55 [00:12<00:11,  2.00it/s]
Loss 0 tensor(0.5618, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4150, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5630, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4180, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5647, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5273):  64%|████████████████████████████████████████████▌                         | 35/55 [00:14<00:08,  2.29it/s]
Loss 0 tensor(0.5612, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4129, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5630, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4126, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5683, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4156, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5625, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4140, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5673, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5096):  75%|████████████████████████████████████████████████████▏                 | 41/55 [00:16<00:04,  2.84it/s]
Loss 0 tensor(0.5671, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4094, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5685, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4092, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5669, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4140, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5644, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4091, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5694, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4065, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5704, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5052):  85%|███████████████████████████████████████████████████████████▊          | 47/55 [00:18<00:02,  2.92it/s]
Loss 0 tensor(0.5701, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4126, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5689, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4071, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5703, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4067, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5680, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4098, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5715, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4032, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5731, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4830):  96%|███████████████████████████████████████████████████████████████████▍  | 53/55 [00:20<00:00,  2.90it/s]
Loss 0 tensor(0.5738, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4043, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5729, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4083, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5689, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4069, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5716, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4050, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5759, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3996, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5762, device='cuda:0', grad_fn=<RsubBackward1>)

Validation: (loss 0.4622):  14%|█████████▊                                                           | 2/14 [00:01<00:09,  1.28it/s]
Loss 0 tensor(0.5770, device='cuda:0', grad_fn=<RsubBackward1>)




Validation: (loss 0.4835):  86%|██████████████████████████████████████████████████████████▎         | 12/14 [00:09<00:01,  1.25it/s]
Loss 0 tensor(0.5759, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3980, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5808, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3996, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5797, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4802):   4%|██▌                                                                    | 2/55 [00:00<00:17,  3.05it/s]
Loss 0 tensor(0.5742, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4011, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5772, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4003, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5793, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3939, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5792, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3911, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5804, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.4000, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5779, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5408):  15%|██████████▎                                                            | 8/55 [00:02<00:15,  2.94it/s]
Loss 0 tensor(0.5777, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3987, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5774, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3922, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5732, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3924, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5797, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4796):  22%|███████████████▎                                                      | 12/55 [00:04<00:14,  2.93it/s]
Loss 0 tensor(0.5802, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3967, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5846, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3910, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5792, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3946, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5854, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4820):  31%|█████████████████████▋                                                | 17/55 [00:06<00:17,  2.15it/s]
Loss 0 tensor(0.5844, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3901, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5913, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3898, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5860, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3869, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5823, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3899, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5825, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3908, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5858, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5167):  40%|████████████████████████████                                          | 22/55 [00:08<00:11,  2.75it/s]
Loss 0 tensor(0.5873, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3873, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5864, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3865, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5826, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3914, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5849, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3912, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5831, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3854, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5868, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4687):  51%|███████████████████████████████████▋                                  | 28/55 [00:10<00:09,  2.90it/s]
Loss 0 tensor(0.5870, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3850, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5868, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3839, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5883, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3819, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5902, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4598):  60%|██████████████████████████████████████████                            | 33/55 [00:12<00:10,  2.09it/s]
Loss 0 tensor(0.5860, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3886, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5923, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3782, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5908, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3807, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5898, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3814, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5915, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.4425):  78%|██████████████████████████████████████████████████████▋               | 43/55 [00:16<00:04,  2.82it/s]
Loss 0 tensor(0.5913, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3835, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5898, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3866, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5871, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3783, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5945, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3845, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5902, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3783, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5902, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3743, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5943, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3778, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5945, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3726, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5921, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3795, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5976, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3718, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5965, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3759, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5984, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.4758):  95%|██████████████████████████████████████████████████████████████████▏   | 52/55 [00:20<00:01,  2.11it/s]
Loss 0 tensor(0.5957, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3807, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5929, device='cuda:0', grad_fn=<RsubBackward1>)

Validation: (loss 0.4970):   7%|████▉                                                                | 1/14 [00:00<00:10,  1.27it/s]
Loss 0 tensor(0.5940, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3761, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5957, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3767, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5919, device='cuda:0', grad_fn=<RsubBackward1>)





Training:   0%|                                                                                              | 0/55 [00:00<?, ?it/s]
Loss 0 tensor(0.6014, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3740, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5915, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3748, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5925, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3730, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5947, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3717, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5946, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4361):   7%|█████▏                                                                 | 4/55 [00:01<00:17,  2.95it/s]
Loss 0 tensor(0.5965, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3701, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5937, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3724, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5985, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3723, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5971, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4594):  16%|███████████▌                                                           | 9/55 [00:04<00:20,  2.20it/s]
Loss 0 tensor(0.6020, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3715, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5994, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3688, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6022, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3687, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6065, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3690, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6005, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3669, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6029, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4152):  27%|███████████████████                                                   | 15/55 [00:06<00:14,  2.82it/s]
Loss 0 tensor(0.6025, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3668, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6064, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3658, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5978, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3697, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6033, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3689, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6037, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3644, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6027, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.4631):  44%|██████████████████████████████▌                                       | 24/55 [00:09<00:14,  2.17it/s]
Loss 0 tensor(0.6037, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3653, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6115, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3654, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6036, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4100):  53%|████████████████████████████████████▉                                 | 29/55 [00:12<00:10,  2.44it/s]
Loss 0 tensor(0.6085, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3599, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6034, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3686, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6025, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3624, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6068, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3613, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6075, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4121):  64%|████████████████████████████████████████████▌                         | 35/55 [00:14<00:07,  2.81it/s]
Loss 0 tensor(0.6032, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3624, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.5998, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3619, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6095, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3595, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6082, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3611, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6083, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3599, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6046, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3581, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6034, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3615, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6066, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3564, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6115, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3570, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6102, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3612, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6102, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3654, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6116, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.3897):  84%|██████████████████████████████████████████████████████████▌           | 46/55 [00:18<00:03,  2.92it/s]
Loss 0 tensor(0.6075, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3578, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6053, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3649, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6093, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3491, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6096, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3568, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6134, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3844):  91%|███████████████████████████████████████████████████████████████▋      | 50/55 [00:19<00:02,  2.32it/s]
Loss 0 tensor(0.6121, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3621, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6080, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3573, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6107, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3599, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6164, device='cuda:0', grad_fn=<RsubBackward1>)

Validation:   0%|                                                                                            | 0/14 [00:00<?, ?it/s]
Loss 0 tensor(0.6073, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3575, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6112, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3519, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6084, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3558, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6120, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3534, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6088, device='cuda:0', grad_fn=<RsubBackward1>)





Validation: (loss 0.4796):  79%|█████████████████████████████████████████████████████▍              | 11/14 [00:09<00:02,  1.22it/s]
Loss 0 tensor(0.6119, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4663):   2%|█▎                                                                     | 1/55 [00:00<00:16,  3.18it/s]
Loss 0 tensor(0.6156, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3507, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6101, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3558, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6096, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3531, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6115, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3490, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6149, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4242):   7%|█████▏                                                                 | 4/55 [00:02<00:29,  1.76it/s]
Loss 0 tensor(0.6113, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3546, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6151, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3506, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6150, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3473, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6176, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3514, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6164, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3491, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6138, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4584):  18%|████████████▋                                                         | 10/55 [00:04<00:16,  2.75it/s]
Loss 0 tensor(0.6117, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3521, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6121, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3485, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6157, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3529, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6210, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4038):  29%|████████████████████▎                                                 | 16/55 [00:06<00:13,  2.90it/s]
Loss 0 tensor(0.6109, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3516, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6202, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3430, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6187, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3480, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6151, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3589):  38%|██████████████████████████▋                                           | 21/55 [00:08<00:17,  1.99it/s]
Loss 0 tensor(0.6178, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3416, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6222, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3448, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6165, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3462, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6214, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3442, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6226, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4991):  45%|███████████████████████████████▊                                      | 25/55 [00:10<00:14,  2.14it/s]
Loss 0 tensor(0.6230, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3388, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6140, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3470, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6227, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3432, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6235, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3479, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6213, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4054):  56%|███████████████████████████████████████▍                              | 31/55 [00:12<00:08,  2.79it/s]
Loss 0 tensor(0.6216, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3439, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6186, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3430, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6241, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3435, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6217, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3466, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6201, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3458, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6187, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4371):  65%|█████████████████████████████████████████████▊                        | 36/55 [00:14<00:06,  2.88it/s]
Loss 0 tensor(0.6210, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3451, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6228, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3415, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6220, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3384, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6260, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3827):  73%|██████████████████████████████████████████████████▉                   | 40/55 [00:16<00:07,  2.11it/s]
Loss 0 tensor(0.6186, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3424, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6229, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3451, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6237, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3430, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6225, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3386, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6237, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3825):  82%|█████████████████████████████████████████████████████████▎            | 45/55 [00:18<00:04,  2.41it/s]
Loss 0 tensor(0.6218, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3384, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6229, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3348, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6245, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3342, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6253, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3362, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6240, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3375, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6252, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3767):  93%|████████████████████████████████████████████████████████████████▉     | 51/55 [00:20<00:01,  2.85it/s]
Loss 0 tensor(0.6286, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3300, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6283, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3291, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6265, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3415, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6313, device='cuda:0', grad_fn=<RsubBackward1>)






Validation: (loss 0.4089):  93%|███████████████████████████████████████████████████████████████▏    | 13/14 [00:10<00:00,  1.25it/s]
Loss 0 tensor(0.6280, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3367, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6273, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3357, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6307, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3345, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6263, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3300, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6290, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3938):   9%|██████▍                                                                | 5/55 [00:01<00:16,  2.95it/s]
Loss 0 tensor(0.6256, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3331, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6302, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3296, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6299, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3408, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6265, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3982):  16%|███████████▌                                                           | 9/55 [00:03<00:21,  2.19it/s]
Loss 0 tensor(0.6269, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3323, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6286, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3426, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6348, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3338, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6302, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3879):  25%|█████████████████▊                                                    | 14/55 [00:05<00:16,  2.52it/s]
Loss 0 tensor(0.6317, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3332, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6327, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3243, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6290, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3262, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6253, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3378, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6287, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3304, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6315, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3727):  36%|█████████████████████████▍                                            | 20/55 [00:07<00:12,  2.87it/s]
Loss 0 tensor(0.6301, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3273, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6293, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3256, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6332, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3292, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6275, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3273, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6360, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3273, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6370, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3572):  47%|█████████████████████████████████                                     | 26/55 [00:09<00:09,  2.91it/s]
Loss 0 tensor(0.6323, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3248, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6396, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3240, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6319, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3776):  53%|████████████████████████████████████▉                                 | 29/55 [00:11<00:14,  1.80it/s]
Loss 0 tensor(0.6347, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3268, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6307, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3284, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6358, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3210, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6312, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3283, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6319, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3270, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6318, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3474):  64%|████████████████████████████████████████████▌                         | 35/55 [00:13<00:07,  2.73it/s]
Loss 0 tensor(0.6342, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3246, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6319, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3231, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6338, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3256, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6394, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3291, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6317, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3246, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6397, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3407):  75%|████████████████████████████████████████████████████▏                 | 41/55 [00:15<00:04,  2.90it/s]
Loss 0 tensor(0.6373, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3165, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6332, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3226, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6321, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3229, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6369, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3857):  82%|█████████████████████████████████████████████████████████▎            | 45/55 [00:17<00:04,  2.06it/s]
Loss 0 tensor(0.6351, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3233, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6380, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3233, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6381, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3236, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6373, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3173, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6388, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3754):  89%|██████████████████████████████████████████████████████████████▎       | 49/55 [00:19<00:02,  2.13it/s]
Loss 0 tensor(0.6347, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3191, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6350, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3213, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6424, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3238, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6350, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3178, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6364, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3187, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6428, device='cuda:0', grad_fn=<RsubBackward1>)






Validation: (loss 0.3966):  86%|██████████████████████████████████████████████████████████▎         | 12/14 [00:09<00:01,  1.27it/s]
Loss 0 tensor(0.6399, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3617):   5%|███▊                                                                   | 3/55 [00:00<00:17,  2.97it/s]
Loss 0 tensor(0.6370, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3190, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6369, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3174, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6379, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3207, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6419, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3183, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6413, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3162, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6429, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3780):  15%|██████████▎                                                            | 8/55 [00:02<00:16,  2.93it/s]
Loss 0 tensor(0.6427, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3151, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6412, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3105, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6407, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3178, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6439, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3162, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6398, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3128, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6433, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3252):  25%|█████████████████▊                                                    | 14/55 [00:04<00:14,  2.92it/s]
Loss 0 tensor(0.6409, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3132, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6447, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3146, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6443, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3103, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6410, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3177, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6435, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3480):  33%|██████████████████████▉                                               | 18/55 [00:06<00:16,  2.20it/s]
Loss 0 tensor(0.6426, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3143, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6444, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3170, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6434, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3156, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6461, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3393):  42%|█████████████████████████████▎                                        | 23/55 [00:08<00:12,  2.46it/s]
Loss 0 tensor(0.6419, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3107, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6419, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3134, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6450, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3095, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6440, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3203, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6462, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3146, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6481, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3834):  53%|████████████████████████████████████▉                                 | 29/55 [00:11<00:09,  2.86it/s]
Loss 0 tensor(0.6455, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3128, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6429, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3099, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6395, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3096, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6405, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3092, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6471, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3468):  62%|███████████████████████████████████████████▎                          | 34/55 [00:12<00:07,  2.92it/s]
Loss 0 tensor(0.6470, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3077, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6435, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3063, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6423, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3727):  67%|███████████████████████████████████████████████                       | 37/55 [00:14<00:10,  1.67it/s]
Loss 0 tensor(0.6511, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3098, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6493, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3052, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6434, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3101, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6512, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3023, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6431, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3118, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6484, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.3416):  89%|██████████████████████████████████████████████████████████████▎       | 49/55 [00:18<00:02,  2.90it/s]
Loss 0 tensor(0.6460, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3091, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6576, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3015, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6459, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3102, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6502, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3048, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6495, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3071, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6405, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3149):  96%|███████████████████████████████████████████████████████████████████▍  | 53/55 [00:20<00:00,  2.92it/s]
Loss 0 tensor(0.6510, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3044, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6483, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2996, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6449, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3088, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6479, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3067, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6504, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3014, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6465, device='cuda:0', grad_fn=<RsubBackward1>)

Validation: (loss 0.3852):  14%|█████████▊                                                           | 2/14 [00:01<00:09,  1.29it/s]
Loss 0 tensor(0.6527, device='cuda:0', grad_fn=<RsubBackward1>)




Validation: (loss 0.4254):  79%|█████████████████████████████████████████████████████▍              | 11/14 [00:09<00:02,  1.21it/s]
Loss 0 tensor(0.6529, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2925):   2%|█▎                                                                     | 1/55 [00:00<00:16,  3.25it/s]
Loss 0 tensor(0.6506, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3013, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6535, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2986, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6485, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3917):   7%|█████▏                                                                 | 4/55 [00:01<00:26,  1.96it/s]
Loss 0 tensor(0.6500, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2990, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6502, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3001, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6509, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3073, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6505, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2993, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6498, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4862):  16%|███████████▌                                                           | 9/55 [00:04<00:18,  2.47it/s]
Loss 0 tensor(0.6482, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3096, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6516, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2996, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6486, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3032, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6517, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3023, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6538, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3078, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6524, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3296):  27%|███████████████████                                                   | 15/55 [00:06<00:13,  2.87it/s]
Loss 0 tensor(0.6484, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3013, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6532, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3076, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6547, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3020, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6553, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3008, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6526, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3023, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6531, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3170):  38%|██████████████████████████▋                                           | 21/55 [00:08<00:11,  2.92it/s]
Loss 0 tensor(0.6495, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2996, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6504, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3016, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6539, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4287):  44%|██████████████████████████████▌                                       | 24/55 [00:10<00:15,  1.99it/s]
Loss 0 tensor(0.6531, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3027, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6552, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2955, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6560, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2989, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6580, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2963, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6553, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2974, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6565, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.3901):  65%|█████████████████████████████████████████████▊                        | 36/55 [00:14<00:06,  2.91it/s]
Loss 0 tensor(0.6582, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2967, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6541, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2990, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6571, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2965, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6551, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3050, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6557, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2988, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6481, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3835):  75%|████████████████████████████████████████████████████▏                 | 41/55 [00:16<00:06,  2.28it/s]
Loss 0 tensor(0.6574, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3069, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6575, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2874, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6580, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2947, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6600, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3427):  82%|█████████████████████████████████████████████████████████▎            | 45/55 [00:18<00:04,  2.41it/s]
Loss 0 tensor(0.6575, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3000, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6564, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2916, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6602, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3045, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6599, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2957, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6613, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2958, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6551, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2952, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6558, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2961, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6597, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.3041, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6544, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2991, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6585, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2904, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6573, device='cuda:0', grad_fn=<RsubBackward1>)


Validation: (loss 0.2942):   7%|████▉                                                                | 1/14 [00:00<00:10,  1.29it/s]
Loss 0 tensor(0.6643, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2894, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6599, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2916, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6553, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2949, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6517, device='cuda:0', grad_fn=<RsubBackward1>)





Validation: (loss 0.3168):  86%|██████████████████████████████████████████████████████████▎         | 12/14 [00:10<00:01,  1.16it/s]
Loss 0 tensor(0.6618, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2921, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6561, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2902, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6606, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3569):   5%|███▊                                                                   | 3/55 [00:00<00:17,  2.98it/s]
Loss 0 tensor(0.6613, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2981, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6602, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2936, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6619, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2917, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6597, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3496):  13%|█████████                                                              | 7/55 [00:03<00:23,  2.06it/s]
Loss 0 tensor(0.6617, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2865, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6600, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2872, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6584, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2891, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6611, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3085):  20%|██████████████                                                        | 11/55 [00:04<00:19,  2.30it/s]
Loss 0 tensor(0.6583, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2913, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6595, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2917, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6605, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2878, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6588, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2916, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6635, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2890, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6594, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.4612):  42%|█████████████████████████████▎                                        | 23/55 [00:09<00:10,  2.91it/s]
Loss 0 tensor(0.6628, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2911, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6614, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2851, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6651, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2869, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6602, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2886, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6638, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2777, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6638, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3565):  47%|█████████████████████████████████                                     | 26/55 [00:10<00:12,  2.26it/s]
Loss 0 tensor(0.6636, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2907, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6662, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2879, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6627, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3169):  58%|████████████████████████████████████████▋                             | 32/55 [00:13<00:08,  2.64it/s]
Loss 0 tensor(0.6638, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2892, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6668, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2870, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6654, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2823, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6591, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2870, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6653, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2891, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6684, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3628):  69%|████████████████████████████████████████████████▎                     | 38/55 [00:15<00:05,  2.89it/s]
Loss 0 tensor(0.6642, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2809, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6618, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2877, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6697, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2847, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6663, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2834, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6696, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2799, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6648, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2810):  76%|█████████████████████████████████████████████████████▍                | 42/55 [00:16<00:04,  2.91it/s]
Loss 0 tensor(0.6641, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2874, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6652, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2806, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6715, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2803, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6673, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3079):  84%|██████████████████████████████████████████████████████████▌           | 46/55 [00:19<00:04,  1.87it/s]
Loss 0 tensor(0.6723, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2755, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6619, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2852, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6682, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2837, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6669, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2625):  95%|██████████████████████████████████████████████████████████████████▏   | 52/55 [00:21<00:01,  2.74it/s]
Loss 0 tensor(0.6720, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2760, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6632, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2780, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6733, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2759, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6724, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2714, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6666, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2794, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6699, device='cuda:0', grad_fn=<RsubBackward1>)

Validation: (loss 0.3901):   7%|████▉                                                                | 1/14 [00:00<00:11,  1.15it/s]
Loss 0 tensor(0.6714, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2764, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6663, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2861, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6751, device='cuda:0', grad_fn=<RsubBackward1>)





Training:   0%|                                                                                              | 0/55 [00:00<?, ?it/s]
Loss 0 tensor(0.6650, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2824, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6735, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2840, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6725, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2799, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6700, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2768, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6678, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2912):  11%|███████▋                                                               | 6/55 [00:02<00:16,  2.94it/s]
Loss 0 tensor(0.6680, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2799, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6736, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2766, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6710, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2863, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6696, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2801, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6663, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2840, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6701, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2510):  20%|██████████████                                                        | 11/55 [00:03<00:15,  2.93it/s]
Loss 0 tensor(0.6711, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2773, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6697, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2763, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6728, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2779, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6737, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2738, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6659, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3468):  29%|████████████████████▎                                                 | 16/55 [00:05<00:15,  2.51it/s]
Loss 0 tensor(0.6738, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2719, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6738, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2712, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6717, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2931):  36%|█████████████████████████▍                                            | 20/55 [00:07<00:16,  2.09it/s]
Loss 0 tensor(0.6770, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2739, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6737, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2681, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6752, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2688, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6749, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2735, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6694, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2751, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6773, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3984):  47%|█████████████████████████████████                                     | 26/55 [00:09<00:10,  2.79it/s]
Loss 0 tensor(0.6719, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2850, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6748, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2755, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6741, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2744, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6790, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2715, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6744, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2665, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6788, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.2596):  65%|█████████████████████████████████████████████▊                        | 36/55 [00:13<00:08,  2.26it/s]
Loss 0 tensor(0.6768, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2751, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6750, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2741, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6746, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2831, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6776, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2970):  75%|████████████████████████████████████████████████████▏                 | 41/55 [00:16<00:05,  2.54it/s]
Loss 0 tensor(0.6709, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2717, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6756, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2715, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6804, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2735, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6804, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2716, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6755, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2725, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6774, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2703, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6760, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2743, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6726, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2710, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6772, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2693, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6769, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2397):  85%|███████████████████████████████████████████████████████████▊          | 47/55 [00:18<00:02,  2.87it/s]
Loss 0 tensor(0.6807, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2644, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6780, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2659, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6770, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2708, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6793, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2686, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6761, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2701, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6785, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3054):  95%|██████████████████████████████████████████████████████████████████▏   | 52/55 [00:19<00:01,  2.91it/s]
Loss 0 tensor(0.6782, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2720, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6741, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2755, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6744, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2686, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6738, device='cuda:0', grad_fn=<RsubBackward1>)






Validation: (loss 0.3130):  93%|███████████████████████████████████████████████████████████████▏    | 13/14 [00:11<00:00,  1.20it/s]
Loss 0 tensor(0.6745, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2741, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6824, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2983):   4%|██▌                                                                    | 2/55 [00:00<00:23,  2.29it/s]
Loss 0 tensor(0.6762, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2708, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6772, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2757, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6795, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2703, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6845, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2673, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6755, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3034):  15%|██████████▎                                                            | 8/55 [00:03<00:17,  2.69it/s]
Loss 0 tensor(0.6762, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2730, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6817, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2644, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6855, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2597, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6861, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2583, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6839, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2612, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6808, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2301):  24%|████████████████▌                                                     | 13/55 [00:05<00:14,  2.88it/s]
Loss 0 tensor(0.6843, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2649, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6832, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2633, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6819, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2661, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6830, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2568, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6826, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2622, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6857, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2328):  35%|████████████████████████▏                                             | 19/55 [00:07<00:12,  2.82it/s]
Loss 0 tensor(0.6850, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2633, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6847, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2632, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6800, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2931):  40%|████████████████████████████                                          | 22/55 [00:09<00:18,  1.79it/s]
Loss 0 tensor(0.6884, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2599, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6762, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2653, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6836, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2632, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6811, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2620, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6833, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2934):  49%|██████████████████████████████████▎                                   | 27/55 [00:10<00:10,  2.65it/s]
Loss 0 tensor(0.6833, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2643, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6833, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2597, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6854, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2679, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6809, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2714, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6801, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2634, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6894, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.2447):  69%|████████████████████████████████████████████████▎                     | 38/55 [00:15<00:08,  1.96it/s]
Loss 0 tensor(0.6810, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2640, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6802, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2646, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6819, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2681, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6869, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2643, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6848, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2510):  76%|█████████████████████████████████████████████████████▍                | 42/55 [00:17<00:06,  2.09it/s]
Loss 0 tensor(0.6827, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2682, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6811, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2655, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6817, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2684, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6875, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3714):  87%|█████████████████████████████████████████████████████████████         | 48/55 [00:19<00:02,  2.79it/s]
Loss 0 tensor(0.6854, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2585, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6843, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2593, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6869, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2549, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6855, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2587, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6840, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2808):  96%|███████████████████████████████████████████████████████████████████▍  | 53/55 [00:21<00:00,  2.90it/s]
Loss 0 tensor(0.6774, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2746, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6857, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2675, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6824, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2587, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6890, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2567, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6845, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2619, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6853, device='cuda:0', grad_fn=<RsubBackward1>)

Validation: (loss 0.6537):   7%|████▉                                                                | 1/14 [00:00<00:10,  1.19it/s]
Loss 0 tensor(0.6856, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2598, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6797, device='cuda:0', grad_fn=<RsubBackward1>)




Validation: (loss 0.5897):  86%|██████████████████████████████████████████████████████████▎         | 12/14 [00:09<00:01,  1.29it/s]
Loss 0 tensor(0.6821, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4402):   2%|█▎                                                                     | 1/55 [00:00<00:17,  3.14it/s]
Loss 0 tensor(0.6822, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2704, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6839, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2633, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6812, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2619, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6921, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2616, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6891, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2564, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6877, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.2556):  24%|████████████████▌                                                     | 13/55 [00:04<00:14,  2.93it/s]
Loss 0 tensor(0.6836, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2650, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6908, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2534, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6872, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2600, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6862, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2590, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6817, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2632, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6840, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2620, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6851, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2549, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6850, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2602, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6850, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2638, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6902, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2631, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6919, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2337):  33%|██████████████████████▉                                               | 18/55 [00:06<00:12,  2.93it/s]
Loss 0 tensor(0.6863, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2601, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6842, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2633, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6957, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2111):  40%|████████████████████████████                                          | 22/55 [00:08<00:16,  1.96it/s]
Loss 0 tensor(0.6886, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2508, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6898, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2556, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6899, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2515, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6920, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2534, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6927, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2450, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6855, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2131):  51%|███████████████████████████████████▋                                  | 28/55 [00:10<00:09,  2.77it/s]
Loss 0 tensor(0.6957, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2481, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6945, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2496, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6898, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2581, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6839, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2617, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6892, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2559, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6893, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2698):  60%|██████████████████████████████████████████                            | 33/55 [00:12<00:07,  2.89it/s]
Loss 0 tensor(0.6911, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2528, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6934, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2543, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6929, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2530, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6932, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.3946):  76%|█████████████████████████████████████████████████████▍                | 42/55 [00:16<00:05,  2.42it/s]
Loss 0 tensor(0.7009, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2488, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6923, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2511, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6929, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2535, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6888, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2510, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6881, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2660, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6974, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2480, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6940, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2517, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6886, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2554, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6889, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2541, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6936, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2531, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6895, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2422):  87%|█████████████████████████████████████████████████████████████         | 48/55 [00:18<00:02,  2.85it/s]
Loss 0 tensor(0.7027, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2447, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6912, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2488, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7007, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2511, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6896, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2549, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6938, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2599, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6950, device='cuda:0', grad_fn=<RsubBackward1>)


Validation: (loss 0.2901):  14%|█████████▊                                                           | 2/14 [00:01<00:09,  1.26it/s]
Loss 0 tensor(0.6839, device='cuda:0', grad_fn=<RsubBackward1>)





Training:   0%|                                                                                              | 0/55 [00:00<?, ?it/s]
Loss 0 tensor(0.6948, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2504, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6961, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2477, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6967, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2457, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6926, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2582, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6915, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2246):  11%|███████▋                                                               | 6/55 [00:02<00:16,  2.94it/s]
Loss 0 tensor(0.6910, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2497, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6977, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2429, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6991, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2563, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6924, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2521, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6936, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2493, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6925, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.3548):  29%|████████████████████▎                                                 | 16/55 [00:05<00:13,  2.93it/s]
Loss 0 tensor(0.6959, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2497, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6913, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2544, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6955, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2492, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6993, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2551, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6927, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2293):  38%|██████████████████████████▋                                           | 21/55 [00:08<00:15,  2.26it/s]
Loss 0 tensor(0.6926, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2521, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7018, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2430, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6885, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2607, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6943, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2111):  49%|██████████████████████████████████▎                                   | 27/55 [00:10<00:09,  2.83it/s]
Loss 0 tensor(0.6906, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2511, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6997, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2459, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6951, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2513, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6962, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2461, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6956, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2502, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6942, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2735):  60%|██████████████████████████████████████████                            | 33/55 [00:12<00:07,  2.91it/s]
Loss 0 tensor(0.6970, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2443, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6997, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2440, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6948, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2509, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6975, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2474, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6906, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2544, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6943, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2612):  71%|█████████████████████████████████████████████████▋                    | 39/55 [00:14<00:05,  2.92it/s]
Loss 0 tensor(0.6974, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2508, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6975, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2448, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6958, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2446, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7041, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2403, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6996, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2450, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7022, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2620):  82%|█████████████████████████████████████████████████████████▎            | 45/55 [00:16<00:03,  2.92it/s]
Loss 0 tensor(0.7044, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2455, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6990, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2398, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7025, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2429, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6958, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2441, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6955, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2488, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6994, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2255):  89%|██████████████████████████████████████████████████████████████▎       | 49/55 [00:17<00:02,  2.92it/s]
Loss 0 tensor(0.6979, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2470, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6991, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2476, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7021, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2457, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6977, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2412, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6989, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2052):  96%|███████████████████████████████████████████████████████████████████▍  | 53/55 [00:20<00:01,  1.99it/s]
Loss 0 tensor(0.7001, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2431, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6971, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2442, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6974, device='cuda:0', grad_fn=<RsubBackward1>)

Validation: (loss 0.2261):  14%|█████████▊                                                           | 2/14 [00:01<00:09,  1.29it/s]
Loss 0 tensor(0.6992, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2411, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7018, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2442, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7011, device='cuda:0', grad_fn=<RsubBackward1>)






Training: (loss 0.2902):   4%|██▌                                                                    | 2/55 [00:01<00:33,  1.56it/s]
Loss 0 tensor(0.7082, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2424, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7040, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2349):  13%|█████████                                                              | 7/55 [00:03<00:20,  2.38it/s]
Loss 0 tensor(0.7053, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2371, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6992, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2436, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7040, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2412, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6940, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2503, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6988, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2367):  24%|████████████████▌                                                     | 13/55 [00:05<00:14,  2.85it/s]
Loss 0 tensor(0.6973, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2489, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7065, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2402, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6982, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2481, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7081, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2344, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6966, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2518, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7006, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2296):  35%|████████████████████████▏                                             | 19/55 [00:07<00:12,  2.91it/s]
Loss 0 tensor(0.7058, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2387, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7001, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2402, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6982, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2444, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7048, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2373, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7074, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2400, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7085, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2368):  40%|████████████████████████████                                          | 22/55 [00:09<00:17,  1.86it/s]
Loss 0 tensor(0.7033, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2353, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7026, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2461, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.6989, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2408):  51%|███████████████████████████████████▋                                  | 28/55 [00:11<00:09,  2.74it/s]
Loss 0 tensor(0.7133, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2344, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7014, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2388, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7010, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2405, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7097, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2385, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7067, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2415, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7066, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2492):  62%|███████████████████████████████████████████▎                          | 34/55 [00:13<00:07,  2.90it/s]
Loss 0 tensor(0.7018, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2408, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7040, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2367, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7083, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2366, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7069, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2413, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7024, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2426, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7080, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2735):  69%|████████████████████████████████████████████████▎                     | 38/55 [00:15<00:06,  2.65it/s]
Loss 0 tensor(0.7047, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2399, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7077, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2346, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7045, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2327, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7011, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2390):  76%|█████████████████████████████████████████████████████▍                | 42/55 [00:17<00:06,  1.91it/s]
Loss 0 tensor(0.7112, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2361, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7042, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2410, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7074, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2345, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7050, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2084):  87%|█████████████████████████████████████████████████████████████         | 48/55 [00:19<00:02,  2.75it/s]
Loss 0 tensor(0.7047, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2339, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7106, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2365, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7117, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2380, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7069, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2421, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7054, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2335, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7083, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2111):  98%|████████████████████████████████████████████████████████████████████▋ | 54/55 [00:21<00:00,  2.90it/s]
Loss 0 tensor(0.7128, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2320, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7141, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2346, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7090, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2337, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7105, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2329, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7114, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2319, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7055, device='cuda:0', grad_fn=<RsubBackward1>)

Validation: (loss 0.2504):  14%|█████████▊                                                           | 2/14 [00:01<00:09,  1.23it/s]
Loss 0 tensor(0.7147, device='cuda:0', grad_fn=<RsubBackward1>)






Training: (loss 0.2299):  11%|███████▋                                                               | 6/55 [00:02<00:16,  2.94it/s]
Loss 0 tensor(0.7096, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2332, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7100, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2364, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7190, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2253, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7062, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2376, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7015, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2422, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7099, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2058):  22%|███████████████▎                                                      | 12/55 [00:04<00:14,  2.93it/s]
Loss 0 tensor(0.7058, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2376, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7166, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2309, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7166, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2306, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7084, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2392, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7136, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2366, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7074, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2045):  27%|███████████████████                                                   | 15/55 [00:06<00:23,  1.72it/s]
Loss 0 tensor(0.7068, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2350, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7138, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2356, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7138, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3019):  38%|██████████████████████████▋                                           | 21/55 [00:08<00:12,  2.69it/s]
Loss 0 tensor(0.7082, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2353, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7109, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2324, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7087, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2339, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7177, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2260, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7154, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2326, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7099, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2032):  49%|██████████████████████████████████▎                                   | 27/55 [00:10<00:09,  2.89it/s]
Loss 0 tensor(0.7111, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2303, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7111, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2356, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7155, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2414, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7083, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2357, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7105, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.1994):  56%|███████████████████████████████████████▍                              | 31/55 [00:11<00:08,  2.91it/s]
Loss 0 tensor(0.7118, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2305, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7093, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2302, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7152, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2381, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7061, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2459, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7148, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2577):  65%|█████████████████████████████████████████████▊                        | 36/55 [00:14<00:08,  2.32it/s]
Loss 0 tensor(0.7158, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2263, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7138, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2306, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7165, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2372, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7083, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2677):  75%|████████████████████████████████████████████████████▏                 | 41/55 [00:16<00:04,  2.80it/s]
Loss 0 tensor(0.7117, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2374, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7121, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2316, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7142, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2236, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7116, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2298, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7142, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2273, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7096, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.1604):  85%|███████████████████████████████████████████████████████████▊          | 47/55 [00:18<00:02,  2.90it/s]
Loss 0 tensor(0.7145, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2263, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7093, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2344, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7149, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2245, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7102, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2355, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7142, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2271, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7190, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2286):  96%|███████████████████████████████████████████████████████████████████▍  | 53/55 [00:20<00:00,  2.91it/s]
Loss 0 tensor(0.7100, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2368, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7138, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2356, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7127, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2302, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7122, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2355, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7158, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2262, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7179, device='cuda:0', grad_fn=<RsubBackward1>)

Validation: (loss 0.2840):  14%|█████████▊                                                           | 2/14 [00:01<00:09,  1.29it/s]
Loss 0 tensor(0.7210, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2206, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7134, device='cuda:0', grad_fn=<RsubBackward1>)






Training: (loss 0.2351):   9%|██████▍                                                                | 5/55 [00:01<00:18,  2.76it/s]
Loss 0 tensor(0.7150, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2279, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7152, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2363, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7168, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2253, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7142, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2302, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7212, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2099):  20%|██████████████                                                        | 11/55 [00:03<00:15,  2.91it/s]
Loss 0 tensor(0.7183, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2264, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7254, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2213, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7226, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2231, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7134, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2279, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7132, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.1920):  31%|█████████████████████▋                                                | 17/55 [00:06<00:13,  2.92it/s]
Loss 0 tensor(0.7128, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2279, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7229, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2223, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7155, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2301, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7232, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2238, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7201, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2222, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7203, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2015):  36%|█████████████████████████▍                                            | 20/55 [00:08<00:19,  1.81it/s]
Loss 0 tensor(0.7194, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2254, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7155, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2300, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7178, device='cuda:0', grad_fn=<RsubBackward1>)
Traceback (most recent call last):
  File "main.py", line 111, in <module>
    init_and_train_model(args.verbose)
  File "main.py", line 79, in init_and_train_model
    DeepSeg.train_model()
  File "/root/research/deep-segmentation/segmentation/unet/segmentation.py", line 235, in train_model
    training_losses, validation_losses, lr_rates = trainer.run_trainer()
  File "/root/research/deep-segmentation/segmentation/unet/trainer.py", line 59, in run_trainer
    self._train()
  File "/root/research/deep-segmentation/segmentation/unet/trainer.py", line 100, in _train
    for i, (x, y) in batch_iter:
  File "/usr/local/lib/python3.8/dist-packages/tqdm/std.py", line 1180, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/root/research/deep-segmentation/segmentation/unet/customdatasets3.py", line 56, in __getitem__
    x, y = self.transform(x, y)
  File "/root/research/deep-segmentation/segmentation/unet/transformations.py", line 132, in __call__
    inp, target = t(inp, target)
  File "/root/research/deep-segmentation/segmentation/unet/transformations.py", line 114, in __call__
    if self.target: tar = self.function(tar)
  File "/root/research/deep-segmentation/segmentation/unet/transformations.py", line 31, in create_dense_target
    classes = np.unique(tar)
  File "<__array_function__ internals>", line 5, in unique
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/arraysetops.py", line 262, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "/usr/local/lib/python3.8/dist-packages/numpy/lib/arraysetops.py", line 323, in _unique1d
    ar.sort()
KeyboardInterrupt
Loss 0 tensor(0.7168, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2285, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7111, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2342, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7193, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2284, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7169, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2358, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7174, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2264, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7166, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2254, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 0 tensor(0.7168, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(0.2244, device='cuda:0', grad_fn=<RsubBackward1>)