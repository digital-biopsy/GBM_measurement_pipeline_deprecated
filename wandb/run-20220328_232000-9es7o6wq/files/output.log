
######################### Loading and Augmenting Images #########################
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Progress:   0%|                                                                                              | 0/90 [00:00<?, ?it/s]
Training: (loss 0.9301):   2%|█▎                                                                     | 1/55 [00:00<00:22,  2.38it/s]
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 32, 512, 512]             320
              ReLU-2         [-1, 32, 512, 512]               0
       BatchNorm2d-3         [-1, 32, 512, 512]              64
            Conv2d-4         [-1, 32, 512, 512]           9,248
              ReLU-5         [-1, 32, 512, 512]               0
       BatchNorm2d-6         [-1, 32, 512, 512]              64
         MaxPool2d-7         [-1, 32, 256, 256]               0
         DownBlock-8  [[-1, 32, 256, 256], [-1, 32, 512, 512]]               0
            Conv2d-9         [-1, 64, 256, 256]          18,496
             ReLU-10         [-1, 64, 256, 256]               0
      BatchNorm2d-11         [-1, 64, 256, 256]             128
           Conv2d-12         [-1, 64, 256, 256]          36,928
             ReLU-13         [-1, 64, 256, 256]               0
      BatchNorm2d-14         [-1, 64, 256, 256]             128
        MaxPool2d-15         [-1, 64, 128, 128]               0
        DownBlock-16  [[-1, 64, 128, 128], [-1, 64, 256, 256]]               0
           Conv2d-17        [-1, 128, 128, 128]          73,856
             ReLU-18        [-1, 128, 128, 128]               0
      BatchNorm2d-19        [-1, 128, 128, 128]             256
           Conv2d-20        [-1, 128, 128, 128]         147,584
             ReLU-21        [-1, 128, 128, 128]               0
      BatchNorm2d-22        [-1, 128, 128, 128]             256
        MaxPool2d-23          [-1, 128, 64, 64]               0
        DownBlock-24  [[-1, 128, 64, 64], [-1, 128, 128, 128]]               0
           Conv2d-25          [-1, 256, 64, 64]         295,168
             ReLU-26          [-1, 256, 64, 64]               0
      BatchNorm2d-27          [-1, 256, 64, 64]             512
           Conv2d-28          [-1, 256, 64, 64]         590,080
             ReLU-29          [-1, 256, 64, 64]               0
      BatchNorm2d-30          [-1, 256, 64, 64]             512
        DownBlock-31  [[-1, 256, 64, 64], [-1, 256, 64, 64]]               0
  ConvTranspose2d-32        [-1, 128, 128, 128]         131,200
             ReLU-33        [-1, 128, 128, 128]               0
      BatchNorm2d-34        [-1, 128, 128, 128]             256
      Concatenate-35        [-1, 256, 128, 128]               0
           Conv2d-36        [-1, 128, 128, 128]         295,040
             ReLU-37        [-1, 128, 128, 128]               0
      BatchNorm2d-38        [-1, 128, 128, 128]             256
           Conv2d-39        [-1, 128, 128, 128]         147,584
             ReLU-40        [-1, 128, 128, 128]               0
      BatchNorm2d-41        [-1, 128, 128, 128]             256
          UpBlock-42        [-1, 128, 128, 128]               0
  ConvTranspose2d-43         [-1, 64, 256, 256]          32,832
             ReLU-44         [-1, 64, 256, 256]               0
      BatchNorm2d-45         [-1, 64, 256, 256]             128
      Concatenate-46        [-1, 128, 256, 256]               0
           Conv2d-47         [-1, 64, 256, 256]          73,792
             ReLU-48         [-1, 64, 256, 256]               0
      BatchNorm2d-49         [-1, 64, 256, 256]             128
           Conv2d-50         [-1, 64, 256, 256]          36,928
             ReLU-51         [-1, 64, 256, 256]               0
      BatchNorm2d-52         [-1, 64, 256, 256]             128
          UpBlock-53         [-1, 64, 256, 256]               0
  ConvTranspose2d-54         [-1, 32, 512, 512]           8,224
             ReLU-55         [-1, 32, 512, 512]               0
      BatchNorm2d-56         [-1, 32, 512, 512]              64
      Concatenate-57         [-1, 64, 512, 512]               0
           Conv2d-58         [-1, 32, 512, 512]          18,464
             ReLU-59         [-1, 32, 512, 512]               0
      BatchNorm2d-60         [-1, 32, 512, 512]              64
           Conv2d-61         [-1, 32, 512, 512]           9,248
             ReLU-62         [-1, 32, 512, 512]               0
      BatchNorm2d-63         [-1, 32, 512, 512]              64
          UpBlock-64         [-1, 32, 512, 512]               0
           Conv2d-65          [-1, 2, 512, 512]              66
================================================================
Total params: 1,928,322
Trainable params: 1,928,322
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 1.00
Forward/backward pass size (MB): 184547280.00
Params size (MB): 7.36
Estimated Total Size (MB): 184547288.36
----------------------------------------------------------------
######################### Start Training #########################
Loss 0 tensor(0.5041, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.7882):  13%|█████████                                                              | 7/55 [00:02<00:16,  2.91it/s]
Loss 0 tensor(0.5091, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.5551, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5110, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.8552, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5077, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(14.3180, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5125, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.4278, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5108, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(16.0459, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5184, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.7522):  24%|████████████████▌                                                     | 13/55 [00:04<00:14,  2.92it/s]
Loss 0 tensor(0.5143, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(14.0370, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5176, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(17.2088, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5233, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.3862, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5195, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.9910, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5186, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(15.7540, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5276, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.4543, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5276, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.4930, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5261, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.7216, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5279, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.4997, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5264, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.7554):  31%|█████████████████████▋                                                | 17/55 [00:06<00:18,  2.05it/s]
Loss 0 tensor(0.5398, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(17.9608, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5327, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(16.5404, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5385, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.3825, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5342, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.6603):  49%|██████████████████████████████████▎                                   | 27/55 [00:10<00:10,  2.78it/s]
Loss 0 tensor(0.5407, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.7181, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5371, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(18.4757, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5451, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.4740, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5470, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.6161, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5403, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(16.6070, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5470, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.6557):  60%|██████████████████████████████████████████                            | 33/55 [00:12<00:07,  2.90it/s]
Loss 0 tensor(0.5433, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.2910, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5512, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(20.2683, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5462, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.8473, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5477, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(18.0583, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5507, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.6279):  71%|█████████████████████████████████████████████████▋                    | 39/55 [00:14<00:05,  2.83it/s]
Loss 0 tensor(0.5518, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(20.9580, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5512, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.2922, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5608, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.6086, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5520, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.0484, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5573, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(18.3927, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5542, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.6311):  78%|██████████████████████████████████████████████████████▋               | 43/55 [00:16<00:05,  2.22it/s]
Loss 0 tensor(0.5596, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.5595, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5579, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.2390, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5581, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(20.2099, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5581, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(19.6666, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5588, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.1995, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5668, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.1157, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5665, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(16.7051, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5704, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(19.6609, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5639, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5988):  85%|███████████████████████████████████████████████████████████▊          | 47/55 [00:18<00:03,  2.37it/s]
Loss 0 tensor(0.5769, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.2232, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5623, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(20.4173, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5687, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.6768, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5741, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.3638, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5666, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.6668, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5704, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.6020):  96%|███████████████████████████████████████████████████████████████████▍  | 53/55 [00:20<00:00,  2.85it/s]
Loss 0 tensor(0.5709, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(19.4719, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5747, device='cuda:0', grad_fn=<RsubBackward1>)





Validation: (loss 0.6827):  86%|██████████████████████████████████████████████████████████▎         | 12/14 [00:09<00:01,  1.25it/s]
Loss 0 tensor(0.5732, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5900):   4%|██▌                                                                    | 2/55 [00:00<00:17,  3.04it/s]
Loss 0 tensor(0.5719, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.3186, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5721, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(19.3144, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5751, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.7019, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5807, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.6565, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5744, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(19.0273, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5800, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5766):  13%|█████████                                                              | 7/55 [00:02<00:16,  2.93it/s]
Loss 0 tensor(0.5874, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.8716, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5816, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.1992, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5771, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5290):  20%|██████████████                                                        | 11/55 [00:04<00:21,  2.07it/s]
Loss 0 tensor(0.5866, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.9500, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5785, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.1391, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5890, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.2184, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5851, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.5178, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5838, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.8152, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5958, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5611):  31%|█████████████████████▋                                                | 17/55 [00:06<00:13,  2.80it/s]
Loss 0 tensor(0.5859, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.4393, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5856, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.5260, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5895, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.0041, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5916, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.3454, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5933, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.4749, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5856, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5526):  42%|█████████████████████████████▎                                        | 23/55 [00:08<00:10,  2.92it/s]
Loss 0 tensor(0.5859, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.9573, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5822, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.7448, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5910, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.2129, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5939, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5403):  49%|██████████████████████████████████▎                                   | 27/55 [00:10<00:12,  2.20it/s]
Loss 0 tensor(0.5959, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.4621, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5903, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.7994, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5986, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.1059, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5987, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.7079, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5983, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5434):  58%|████████████████████████████████████████▋                             | 32/55 [00:12<00:09,  2.55it/s]
Loss 0 tensor(0.5979, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(20.8127, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6069, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(41.9747, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5979, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.8048, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6011, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.9487, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5966, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.8437, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.5987, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5415):  69%|████████████████████████████████████████████████▎                     | 38/55 [00:14<00:05,  2.88it/s]
Loss 0 tensor(0.5994, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.9929, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6023, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.3553, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6067, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.8922, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6015, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.9338, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6062, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.1024, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6013, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5093):  80%|████████████████████████████████████████████████████████              | 44/55 [00:16<00:03,  2.84it/s]
Loss 0 tensor(0.6064, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.1210, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6040, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.2493, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6099, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.5025):  95%|██████████████████████████████████████████████████████████████████▏   | 52/55 [00:20<00:01,  2.60it/s]
Loss 0 tensor(0.6075, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.2262, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6090, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.4515, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6063, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.9579, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6135, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.4976, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6028, device='cuda:0', grad_fn=<RsubBackward1>)

Validation: (loss 0.5624):   7%|████▉                                                                | 1/14 [00:00<00:10,  1.30it/s]
Loss 0 tensor(0.6117, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.8825, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6143, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(33.7329, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6066, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.9925, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6134, device='cuda:0', grad_fn=<RsubBackward1>)





Training: (loss 0.5379):   2%|█▎                                                                     | 1/55 [00:00<00:16,  3.20it/s]
Loss 0 tensor(0.6068, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.8957, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6084, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(39.6917, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6111, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.2212, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6119, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.6129, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6165, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4883):  13%|█████████                                                              | 7/55 [00:02<00:16,  2.93it/s]
Loss 0 tensor(0.6128, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.4765, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6147, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.5644, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6116, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.5357, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6133, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.5072, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6168, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(34.2803, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6163, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5206):  20%|██████████████                                                        | 11/55 [00:03<00:15,  2.93it/s]
Loss 0 tensor(0.6106, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.1919, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6212, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.3803, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6185, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.9894, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6209, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.3287, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6172, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.9411, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6201, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.4866):  36%|█████████████████████████▍                                            | 20/55 [00:07<00:20,  1.72it/s]
Loss 0 tensor(0.6221, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.8712, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6251, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.3307, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6200, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4997):  47%|█████████████████████████████████                                     | 26/55 [00:09<00:10,  2.71it/s]
Loss 0 tensor(0.6182, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.5796, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6173, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.1496, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6163, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.9694, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6225, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.1867, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6190, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(41.6603, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6209, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4745):  58%|████████████████████████████████████████▋                             | 32/55 [00:11<00:07,  2.90it/s]
Loss 0 tensor(0.6250, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(35.7684, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6210, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.9838, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6191, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.5360, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6228, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(33.7755, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6328, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.0972, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6204, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.5044):  67%|███████████████████████████████████████████████                       | 37/55 [00:13<00:06,  2.92it/s]
Loss 0 tensor(0.6317, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.4161, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6250, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.8023, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6245, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.2085, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6326, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.4875, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6293, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4699):  73%|██████████████████████████████████████████████████▉                   | 40/55 [00:15<00:09,  1.65it/s]
Loss 0 tensor(0.6323, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.4541, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6320, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(40.6037, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6354, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4682):  84%|██████████████████████████████████████████████████████████▌           | 46/55 [00:17<00:03,  2.68it/s]
Loss 0 tensor(0.6289, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.6211, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6278, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(38.7618, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6323, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(39.1798, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6287, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.1263, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6267, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.6056, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6323, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4726):  95%|██████████████████████████████████████████████████████████████████▏   | 52/55 [00:19<00:01,  2.90it/s]
Loss 0 tensor(0.6322, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.9882, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6254, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.9287, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6356, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(46.6124, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6338, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(34.1753, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6311, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.6771, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6452, device='cuda:0', grad_fn=<RsubBackward1>)

Validation: (loss 0.4755):   7%|████▉                                                                | 1/14 [00:00<00:10,  1.19it/s]
Loss 0 tensor(0.6339, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(35.5556, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6322, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.2410, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6289, device='cuda:0', grad_fn=<RsubBackward1>)





Training: (loss 0.4534):   2%|█▎                                                                     | 1/55 [00:00<00:16,  3.31it/s]
Loss 0 tensor(0.6393, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(34.9255, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6443, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(34.5300, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6381, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(44.3273, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6354, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(33.8687, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6353, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.4658, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6323, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4504):  13%|█████████                                                              | 7/55 [00:02<00:16,  2.94it/s]
Loss 0 tensor(0.6329, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(40.5748, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6378, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.1434, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6353, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.5288, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6377, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.0168, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6382, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.4423):  27%|███████████████████                                                   | 15/55 [00:06<00:20,  1.91it/s]
Loss 0 tensor(0.6387, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(38.9594, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6259, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(37.5817, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6363, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.6696, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6384, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(19.1776, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6409, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.6315, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6348, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.3623, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6443, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.0654, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6450, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.9813, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6396, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(43.1797, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6428, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4433):  38%|██████████████████████████▋                                           | 21/55 [00:08<00:12,  2.76it/s]
Loss 0 tensor(0.6372, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.8508, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6377, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.9328, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6404, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.1341, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6405, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.5910, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6447, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.4143, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6471, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4515):  49%|██████████████████████████████████▎                                   | 27/55 [00:10<00:09,  2.90it/s]
Loss 0 tensor(0.6431, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(43.5204, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6390, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(40.7295, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6434, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.9968, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6472, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(41.6284, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6457, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4772):  58%|████████████████████████████████████████▋                             | 32/55 [00:12<00:07,  2.93it/s]
Loss 0 tensor(0.6411, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.3525, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6387, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.6087, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6447, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4643):  65%|█████████████████████████████████████████████▊                        | 36/55 [00:14<00:09,  2.00it/s]
Loss 0 tensor(0.6446, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.2616, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6506, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(33.7557, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6486, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.2728, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6471, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.5734, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6459, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.2698, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6469, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4623):  76%|█████████████████████████████████████████████████████▍                | 42/55 [00:16<00:04,  2.75it/s]
Loss 0 tensor(0.6446, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.4524, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6473, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.2058, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6488, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.5036, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6515, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.1621, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6439, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.0467, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6430, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4783):  85%|███████████████████████████████████████████████████████████▊          | 47/55 [00:18<00:02,  2.90it/s]
Loss 0 tensor(0.6565, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.8447, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6563, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(47.2914, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6480, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.6716, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6492, device='cuda:0', grad_fn=<RsubBackward1>)


Validation:   0%|                                                                                            | 0/14 [00:00<?, ?it/s]
Loss 0 tensor(0.6441, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.3019, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6569, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.2120, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6606, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(40.5237, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6515, device='cuda:0', grad_fn=<RsubBackward1>)





Validation: (loss 0.4389):  93%|███████████████████████████████████████████████████████████████▏    | 13/14 [00:10<00:00,  1.20it/s]
Loss 0 tensor(0.6525, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.7526, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6541, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.5635, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6518, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4583):   5%|███▊                                                                   | 3/55 [00:01<00:19,  2.62it/s]
Loss 0 tensor(0.6565, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(42.2357, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6520, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.8225, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6539, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4737):  13%|█████████                                                              | 7/55 [00:03<00:25,  1.92it/s]
Loss 0 tensor(0.6442, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.8422, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6500, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.9519, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6547, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(60.9558, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6521, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.8801, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6560, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.2129, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6581, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4758):  24%|████████████████▌                                                     | 13/55 [00:05<00:15,  2.77it/s]
Loss 0 tensor(0.6503, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.6064, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6689, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(33.1931, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6577, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(34.4008, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6490, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(49.6403, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6600, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.5194, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6546, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4388):  35%|████████████████████████▏                                             | 19/55 [00:07<00:12,  2.90it/s]
Loss 0 tensor(0.6536, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.6785, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6538, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(33.5481, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6544, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.7517, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6577, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4411):  42%|█████████████████████████████▎                                        | 23/55 [00:09<00:13,  2.29it/s]
Loss 0 tensor(0.6582, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(20.6501, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6608, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.3171, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6593, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(39.6191, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6569, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4705):  49%|██████████████████████████████████▎                                   | 27/55 [00:11<00:12,  2.30it/s]
Loss 0 tensor(0.6545, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(39.0279, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6562, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.9769, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6501, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.7261, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6484, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.1753, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6609, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(33.7712, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6559, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3924):  60%|██████████████████████████████████████████                            | 33/55 [00:13<00:07,  2.84it/s]
Loss 0 tensor(0.6612, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.7817, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6629, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.9152, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6620, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.7518, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6599, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.4125, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6585, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.9655, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6624, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4061):  71%|█████████████████████████████████████████████████▋                    | 39/55 [00:15<00:05,  2.91it/s]
Loss 0 tensor(0.6648, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.1992, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6514, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.6077, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6533, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4599):  75%|████████████████████████████████████████████████████▏                 | 41/55 [00:16<00:06,  2.15it/s]
Loss 0 tensor(0.6581, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.4046, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6692, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.6035, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6566, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.0397, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6649, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(33.2021, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6670, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4298):  85%|███████████████████████████████████████████████████████████▊          | 47/55 [00:19<00:03,  2.58it/s]
Loss 0 tensor(0.6606, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(43.0296, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6638, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(35.0808, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6661, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.8693, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6492, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.9217, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6626, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(37.9588, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6679, device='cuda:0', grad_fn=<RsubBackward1>)


Validation: (loss 0.4409):  14%|█████████▊                                                           | 2/14 [00:01<00:09,  1.30it/s]
Loss 0 tensor(0.6605, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.5954, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6626, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(17.7210, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6683, device='cuda:0', grad_fn=<RsubBackward1>)





Training:   0%|                                                                                              | 0/55 [00:00<?, ?it/s]
Loss 0 tensor(0.6586, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.9813, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6639, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(34.7443, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6646, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.2530, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6659, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(46.9081, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6626, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4193):   9%|██████▍                                                                | 5/55 [00:01<00:16,  2.97it/s]
Loss 0 tensor(0.6647, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.6861, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6736, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(37.3169, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6642, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3801):  16%|███████████▌                                                           | 9/55 [00:03<00:22,  2.02it/s]
Loss 0 tensor(0.6747, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.7095, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6710, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(38.5993, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6656, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.9074, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6605, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.0208, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6660, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.0730, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6682, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4260):  27%|███████████████████                                                   | 15/55 [00:06<00:14,  2.79it/s]
Loss 0 tensor(0.6634, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(20.3457, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6630, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.7012, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6660, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(33.5756, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6662, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.1046, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6741, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.7448, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6635, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4783):  36%|█████████████████████████▍                                            | 20/55 [00:07<00:12,  2.91it/s]
Loss 0 tensor(0.6652, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.3060, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6723, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.2741, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6614, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(37.8737, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6672, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4327):  44%|██████████████████████████████▌                                       | 24/55 [00:09<00:10,  2.91it/s]
Loss 0 tensor(0.6743, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.6306, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6667, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(41.2079, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6649, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.9036, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6628, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.7426, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6678, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4559):  53%|████████████████████████████████████▉                                 | 29/55 [00:11<00:11,  2.21it/s]
Loss 0 tensor(0.6596, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(45.4936, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6695, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(34.8665, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6646, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.4241, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6775, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(38.6098, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6637, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.6685, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6698, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4211):  64%|████████████████████████████████████████████▌                         | 35/55 [00:13<00:07,  2.81it/s]
Loss 0 tensor(0.6688, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(40.3258, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6690, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.9217, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6750, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(37.3637, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6712, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(46.9944, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6745, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.4234):  82%|█████████████████████████████████████████████████████████▎            | 45/55 [00:17<00:04,  2.24it/s]
Loss 0 tensor(0.6679, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(35.3573, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6628, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.2248, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6664, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.9329, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6824, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.2436, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6718, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4033):  89%|██████████████████████████████████████████████████████████████▎       | 49/55 [00:19<00:02,  2.38it/s]
Loss 0 tensor(0.6736, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.8205, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6678, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.3231, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6760, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(42.5945, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6750, device='cuda:0', grad_fn=<RsubBackward1>)

Validation:   0%|                                                                                            | 0/14 [00:00<?, ?it/s]
Loss 0 tensor(0.6731, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.1201, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6665, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.9459, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6650, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.8309, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6801, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.4948, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6745, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.6800, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6815, device='cuda:0', grad_fn=<RsubBackward1>)







Training: (loss 0.3782):   9%|██████▍                                                                | 5/55 [00:01<00:16,  2.96it/s]
Loss 0 tensor(0.6766, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.5842, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6718, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.1739, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6766, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(35.2051, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6719, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.2834, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6729, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4076):  20%|██████████████                                                        | 11/55 [00:03<00:15,  2.93it/s]
Loss 0 tensor(0.6718, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(35.4666, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6680, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.5157, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6798, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(37.8033, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6756, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(39.6484, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6811, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.0133, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6807, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4352):  27%|███████████████████                                                   | 15/55 [00:05<00:20,  1.92it/s]
Loss 0 tensor(0.6854, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(47.7974, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6793, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.0519, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6749, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.0489, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6723, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3757):  35%|████████████████████████▏                                             | 19/55 [00:07<00:16,  2.13it/s]
Loss 0 tensor(0.6816, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.1401, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6695, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.3749, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6845, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.5426, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6798, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3774):  45%|███████████████████████████████▊                                      | 25/55 [00:09<00:10,  2.80it/s]
Loss 0 tensor(0.6729, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(40.7273, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6809, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.2193, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6778, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.4756, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6727, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.1908, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6772, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.2240, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6805, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4096):  56%|███████████████████████████████████████▍                              | 31/55 [00:11<00:08,  2.91it/s]
Loss 0 tensor(0.6792, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.1571, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6839, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.3113, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6755, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(46.1562, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6883, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.8115, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6810, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(37.1604, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6805, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.0167, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6798, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.9313, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6830, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.0340, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6895, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(42.8144, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6880, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3320):  64%|████████████████████████████████████████████▌                         | 35/55 [00:13<00:09,  2.14it/s]
Loss 0 tensor(0.6830, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(39.2718, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6898, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.7129, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6846, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.4358, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6820, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.3927):  84%|██████████████████████████████████████████████████████████▌           | 46/55 [00:17<00:03,  2.87it/s]
Loss 0 tensor(0.6741, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.2429, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6726, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(41.6141, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6864, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(39.0588, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6724, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.8192, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6799, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.5601, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6843, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3906):  95%|██████████████████████████████████████████████████████████████████▏   | 52/55 [00:20<00:01,  2.93it/s]
Loss 0 tensor(0.6910, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(37.3549, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6787, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(20.3422, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6870, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.4572, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6812, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.5798, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6804, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(41.2584, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6762, device='cuda:0', grad_fn=<RsubBackward1>)

Validation:   0%|                                                                                            | 0/14 [00:00<?, ?it/s]
Loss 0 tensor(0.6779, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(52.4700, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6820, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.8087, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6856, device='cuda:0', grad_fn=<RsubBackward1>)

Validation: (loss 0.4052):  14%|█████████▊                                                           | 2/14 [00:01<00:09,  1.29it/s]
Loss 0 tensor(0.6817, device='cuda:0', grad_fn=<RsubBackward1>)





Training:   0%|                                                                                              | 0/55 [00:00<?, ?it/s]
Loss 0 tensor(0.6802, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.0076, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6902, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.0737, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6857, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.8911, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6856, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3718):   9%|██████▍                                                                | 5/55 [00:02<00:25,  1.96it/s]
Loss 0 tensor(0.6865, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(49.4892, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6793, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(48.6487, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6882, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(42.6362, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6848, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.8517, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6822, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4110):  16%|███████████▌                                                           | 9/55 [00:04<00:22,  2.09it/s]
Loss 0 tensor(0.6922, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(19.4333, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6862, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(39.5206, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6867, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(35.0756, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6872, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.6061, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6812, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.0408, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6989, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3667):  27%|███████████████████                                                   | 15/55 [00:06<00:14,  2.80it/s]
Loss 0 tensor(0.6784, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.7683, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6790, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.3309, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6950, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(40.0347, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6952, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(38.9757, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6915, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3608):  38%|██████████████████████████▋                                           | 21/55 [00:08<00:11,  2.91it/s]
Loss 0 tensor(0.6881, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.4722, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6826, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(20.8556, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6877, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.7585, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6922, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.7259, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6889, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3519):  45%|███████████████████████████████▊                                      | 25/55 [00:10<00:14,  2.01it/s]
Loss 0 tensor(0.6879, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.9686, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6900, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.6507, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6899, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.0493, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6868, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3598):  55%|██████████████████████████████████████▏                               | 30/55 [00:12<00:10,  2.45it/s]
Loss 0 tensor(0.6914, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.0122, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6915, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.7604, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6886, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.0926, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6909, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.6521, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6897, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(35.3705, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6884, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.3282):  76%|█████████████████████████████████████████████████████▍                | 42/55 [00:16<00:04,  2.92it/s]
Loss 0 tensor(0.6839, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(18.8503, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6926, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.7393, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6840, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(34.2223, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6948, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(35.1413, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6874, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.9762, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6971, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.4304, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6965, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(33.4806, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7028, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.3988, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6983, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3507):  80%|████████████████████████████████████████████████████████              | 44/55 [00:17<00:04,  2.21it/s]
Loss 0 tensor(0.6961, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(35.8737, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6915, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.9262, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6969, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.7216, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7016, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(20.2292, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6995, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3477):  91%|███████████████████████████████████████████████████████████████▋      | 50/55 [00:20<00:01,  2.61it/s]
Loss 0 tensor(0.6928, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(41.2922, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6924, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.2053, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6912, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.3599, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6955, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.3137, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7017, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(46.6079, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6968, device='cuda:0', grad_fn=<RsubBackward1>)






Validation: (loss 0.3413):  93%|███████████████████████████████████████████████████████████████▏    | 13/14 [00:10<00:00,  1.26it/s]
Loss 0 tensor(0.7016, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.3295, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6981, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.4212, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6981, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3911):   7%|█████▏                                                                 | 4/55 [00:01<00:17,  2.96it/s]
Loss 0 tensor(0.6959, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.2945, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7039, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.1059, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7080, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.4582, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6930, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.5704, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6948, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.2820, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6946, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3730):  18%|████████████▋                                                         | 10/55 [00:03<00:15,  2.93it/s]
Loss 0 tensor(0.6972, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.3167, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6985, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(18.9690, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6936, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(42.1638, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7018, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.2085, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6961, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3658):  29%|████████████████████▎                                                 | 16/55 [00:05<00:13,  2.93it/s]
Loss 0 tensor(0.6979, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(20.2969, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7014, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.6283, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6960, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(39.1495, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6953, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3447):  35%|████████████████████████▏                                             | 19/55 [00:07<00:19,  1.81it/s]
Loss 0 tensor(0.6979, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(40.7403, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6958, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.6231, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6973, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(33.5117, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6937, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.9571, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7016, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3515):  42%|█████████████████████████████▎                                        | 23/55 [00:08<00:12,  2.54it/s]
Loss 0 tensor(0.7053, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(20.7613, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7003, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.0962, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7011, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(42.9240, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6991, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(41.2437, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7045, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.1007, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6996, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3116):  53%|████████████████████████████████████▉                                 | 29/55 [00:10<00:09,  2.84it/s]
Loss 0 tensor(0.7091, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(37.8219, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7115, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(38.7675, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7088, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.4831, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7073, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.5654, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6980, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(40.0330, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6964, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3396):  64%|████████████████████████████████████████████▌                         | 35/55 [00:12<00:06,  2.91it/s]
Loss 0 tensor(0.7135, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.0898, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7084, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.9083, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6999, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3904):  69%|████████████████████████████████████████████████▎                     | 38/55 [00:14<00:08,  2.12it/s]
Loss 0 tensor(0.7048, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(38.1670, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7140, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.6687, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7163, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.2176, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7091, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.9874, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7165, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3227):  78%|██████████████████████████████████████████████████████▋               | 43/55 [00:16<00:04,  2.47it/s]
Loss 0 tensor(0.7045, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(33.2317, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7100, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.2981, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7100, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.1219, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7075, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.1549, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7100, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.5410, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7079, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3415):  89%|██████████████████████████████████████████████████████████████▎       | 49/55 [00:18<00:02,  2.86it/s]
Loss 0 tensor(0.7092, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(33.4288, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7056, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(37.0116, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7086, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(35.2601, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7100, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.5603, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7054, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(33.9848, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7173, device='cuda:0', grad_fn=<RsubBackward1>)






Validation: (loss 0.2773):  86%|██████████████████████████████████████████████████████████▎         | 12/14 [00:09<00:01,  1.23it/s]
Loss 0 tensor(0.7062, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(35.9227, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.6995, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(34.2146, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7132, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3305):   5%|███▊                                                                   | 3/55 [00:01<00:17,  2.95it/s]
Loss 0 tensor(0.7066, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(13.9409, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7089, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3700):   9%|██████▍                                                                | 5/55 [00:02<00:24,  2.01it/s]
Loss 0 tensor(0.7108, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(20.6787, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7085, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.5150, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7097, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.3964, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7129, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.0277, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7156, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(34.5427, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7100, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3944):  20%|██████████████                                                        | 11/55 [00:04<00:16,  2.60it/s]
Loss 0 tensor(0.7101, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.5590, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7117, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.6126, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7147, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(39.7562, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7191, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.3476, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7097, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(35.1261, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7104, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3140):  31%|█████████████████████▋                                                | 17/55 [00:06<00:13,  2.88it/s]
Loss 0 tensor(0.7087, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(40.5623, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7177, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.5712, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7094, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.2626, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7090, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.2221, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7132, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3134):  40%|████████████████████████████                                          | 22/55 [00:08<00:11,  2.92it/s]
Loss 0 tensor(0.7093, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(16.5978, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7134, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.4356, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7151, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.8767, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7189, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.3132):  58%|████████████████████████████████████████▋                             | 32/55 [00:13<00:08,  2.72it/s]
Loss 0 tensor(0.7177, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.0231, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7146, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.2829, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7136, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.2691, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7201, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(20.2206, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7113, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.6023, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7189, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3494):  67%|███████████████████████████████████████████████                       | 37/55 [00:14<00:06,  2.57it/s]
Loss 0 tensor(0.7228, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(40.3499, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7137, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.6158, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7134, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(37.2590, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7202, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.3562, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7093, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(14.7011, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7219, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.2472, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7164, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(42.1725, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7095, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(35.4893, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7084, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3451):  75%|████████████████████████████████████████████████████▏                 | 41/55 [00:16<00:06,  2.08it/s]
Loss 0 tensor(0.7200, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(42.5166, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7153, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.0567, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7224, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(20.6280, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7193, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.3258):  93%|████████████████████████████████████████████████████████████████▉     | 51/55 [00:21<00:01,  2.83it/s]
Loss 0 tensor(0.7226, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(16.9853, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7153, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(34.4729, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7168, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.9200, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7205, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.6455, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7187, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.6652, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7125, device='cuda:0', grad_fn=<RsubBackward1>)

Validation:   0%|                                                                                            | 0/14 [00:00<?, ?it/s]
Loss 0 tensor(0.7151, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.4636, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7167, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.3784, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7224, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.6422, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7135, device='cuda:0', grad_fn=<RsubBackward1>)





Validation: (loss 0.3456):  93%|███████████████████████████████████████████████████████████████▏    | 13/14 [00:10<00:00,  1.24it/s]
Loss 0 tensor(0.7221, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(37.0093, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7121, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(33.9708, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7224, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.6062, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7115, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2937):   9%|██████▍                                                                | 5/55 [00:01<00:17,  2.91it/s]
Loss 0 tensor(0.7153, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(34.3390, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7252, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.7102, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7264, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.5206, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7159, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.1743, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7177, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.9078, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7212, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2813):  20%|██████████████                                                        | 11/55 [00:03<00:15,  2.92it/s]
Loss 0 tensor(0.7249, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.4123, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7239, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.3773, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7182, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(33.9490, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7261, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.6856, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7162, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3254):  27%|███████████████████                                                   | 15/55 [00:05<00:13,  2.92it/s]
Loss 0 tensor(0.7259, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(19.5810, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7276, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(41.2744, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7292, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(19.2816, device='cuda:0', grad_fn=<MaxBackward1>)

Training: (loss 0.2943):  35%|████████████████████████▏                                             | 19/55 [00:07<00:19,  1.88it/s]
Loss 1 tensor(31.1609, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7247, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.8589, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7231, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(19.1809, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7254, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(37.6766, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7232, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.7225, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7231, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3407):  45%|███████████████████████████████▊                                      | 25/55 [00:09<00:10,  2.75it/s]
Loss 0 tensor(0.7225, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.1195, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7202, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.9468, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7308, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.9113, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7257, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(35.9338, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7273, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.6088, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7224, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3003):  56%|███████████████████████████████████████▍                              | 31/55 [00:11<00:08,  2.90it/s]
Loss 0 tensor(0.7154, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.6228, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7196, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.1663, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7205, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.3792, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7258, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.4612, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7252, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.3457):  73%|██████████████████████████████████████████████████▉                   | 40/55 [00:15<00:06,  2.41it/s]
Loss 0 tensor(0.7209, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(39.3949, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7290, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(17.2673, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7288, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.0370, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7383, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2760):  84%|██████████████████████████████████████████████████████████▌           | 46/55 [00:17<00:03,  2.85it/s]
Loss 0 tensor(0.7196, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(40.2733, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7304, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.0108, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7263, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(19.3174, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7290, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.3550, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7298, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.4151, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7298, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3262):  95%|██████████████████████████████████████████████████████████████████▏   | 52/55 [00:20<00:01,  2.91it/s]
Loss 0 tensor(0.7287, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(19.2019, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7316, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.1426, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7252, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(40.5553, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7325, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.6076, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7319, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(18.9696, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7353, device='cuda:0', grad_fn=<RsubBackward1>)

Validation: (loss 0.2895):   7%|████▉                                                                | 1/14 [00:00<00:10,  1.28it/s]
Loss 0 tensor(0.7209, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(15.4236, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7232, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.8627, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7261, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(33.6030, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7359, device='cuda:0', grad_fn=<RsubBackward1>)





Training:   0%|                                                                                              | 0/55 [00:00<?, ?it/s]
Loss 0 tensor(0.7375, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.6676, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7242, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.0691, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7354, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2731):   7%|█████▏                                                                 | 4/55 [00:02<00:29,  1.70it/s]
Loss 0 tensor(0.7373, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.8793, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7271, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.1406, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7228, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.7304, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7333, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.2203, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7241, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.3485, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7299, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2848):  16%|███████████▌                                                           | 9/55 [00:03<00:17,  2.67it/s]
Loss 0 tensor(0.7230, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.4352, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7336, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.5916, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7311, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(35.1021, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7318, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(16.7264, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7324, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2802):  27%|███████████████████                                                   | 15/55 [00:05<00:13,  2.90it/s]
Loss 0 tensor(0.7362, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(18.8365, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7341, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.5905, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7300, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.6970, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7292, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.4194, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7285, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(13.5930, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7327, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2368):  36%|█████████████████████████▍                                            | 20/55 [00:07<00:11,  2.92it/s]
Loss 0 tensor(0.7344, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(40.1650, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7307, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.6176, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7308, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2664):  44%|██████████████████████████████▌                                       | 24/55 [00:09<00:15,  2.00it/s]
Loss 0 tensor(0.7391, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(34.3200, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7411, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(39.1697, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7320, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.3015, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7381, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.1814, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7311, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(19.1360, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7380, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2596):  55%|██████████████████████████████████████▏                               | 30/55 [00:11<00:08,  2.78it/s]
Loss 0 tensor(0.7332, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(37.4202, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7239, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(20.1570, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7332, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.9076, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7298, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.0874, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7384, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.0143, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7333, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2211):  65%|█████████████████████████████████████████████▊                        | 36/55 [00:14<00:06,  2.91it/s]
Loss 0 tensor(0.7401, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.8776, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7440, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.2077, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7365, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.2098, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7209, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.4963, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7284, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2755):  73%|██████████████████████████████████████████████████▉                   | 40/55 [00:15<00:06,  2.30it/s]
Loss 0 tensor(0.7353, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(18.8090, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7320, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.7042, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7418, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.5476, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7370, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2437):  82%|█████████████████████████████████████████████████████████▎            | 45/55 [00:18<00:03,  2.54it/s]
Loss 0 tensor(0.7423, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(37.0649, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7374, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.8531, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7426, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(39.2589, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7304, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(20.4742, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7336, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(13.1823, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7384, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3430):  93%|████████████████████████████████████████████████████████████████▉     | 51/55 [00:20<00:01,  2.87it/s]
Loss 0 tensor(0.7357, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.1911, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7322, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(17.7994, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7372, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.0030, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7356, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.6426, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7377, device='cuda:0', grad_fn=<RsubBackward1>)






Validation: (loss 0.2768):  93%|███████████████████████████████████████████████████████████████▏    | 13/14 [00:10<00:00,  1.25it/s]
Loss 0 tensor(0.7278, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(20.5763, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7408, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(17.2928, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7332, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.7075, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7344, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2860):   7%|█████▏                                                                 | 4/55 [00:01<00:17,  2.98it/s]
Loss 0 tensor(0.7357, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(37.0271, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7365, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.6536, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7417, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(35.9020, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7341, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.4419, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7408, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.8156, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7380, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2425):  18%|████████████▋                                                         | 10/55 [00:03<00:15,  2.93it/s]
Loss 0 tensor(0.7436, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(18.8040, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7367, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.1753, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7367, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.9048, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7353, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(34.5521, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7387, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.4224, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7437, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.2468):  36%|█████████████████████████▍                                            | 20/55 [00:06<00:11,  2.92it/s]
Loss 0 tensor(0.7426, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.1104, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7393, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.7087, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7397, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(17.6035, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7401, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3916):  44%|██████████████████████████████▌                                       | 24/55 [00:09<00:16,  1.86it/s]
Loss 0 tensor(0.7384, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.7802, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7397, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(18.0398, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7501, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(35.1448, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7394, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2635):  55%|██████████████████████████████████████▏                               | 30/55 [00:11<00:09,  2.74it/s]
Loss 0 tensor(0.7413, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(17.8881, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7484, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(18.6158, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7454, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.7141, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7412, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(33.2894, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7354, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(19.8638, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7406, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2792):  65%|█████████████████████████████████████████████▊                        | 36/55 [00:13<00:06,  2.90it/s]
Loss 0 tensor(0.7432, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.6625, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7493, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(39.3214, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7407, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(19.0858, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7331, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.4828, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7480, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(39.1580, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7482, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2368):  76%|█████████████████████████████████████████████████████▍                | 42/55 [00:15<00:04,  2.84it/s]
Loss 0 tensor(0.7425, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(34.3174, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7443, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.2828, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7537, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(34.9859, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7429, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(12.2427, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7438, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.4262):  87%|█████████████████████████████████████████████████████████████         | 48/55 [00:17<00:02,  2.91it/s]
Loss 0 tensor(0.7487, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.0423, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7489, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.5897, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7410, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(27.3914, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7534, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.4949, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7550, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(33.6727, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7533, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2237):  96%|███████████████████████████████████████████████████████████████████▍  | 53/55 [00:19<00:00,  2.92it/s]
Loss 0 tensor(0.7337, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.8983, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7457, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.4318, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7470, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(14.9872, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7451, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.5158, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7438, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.7410, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7458, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(16.5102, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7509, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.7750, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7534, device='cuda:0', grad_fn=<RsubBackward1>)






Training:   0%|                                                                                              | 0/55 [00:00<?, ?it/s]
Loss 0 tensor(0.7442, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(17.3096, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7475, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.9205, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7526, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.5990, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7447, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.2522, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7398, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.0536, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7416, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.3021):  11%|███████▋                                                               | 6/55 [00:02<00:16,  2.94it/s]
Loss 0 tensor(0.7366, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.8203, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7482, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(29.2491, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7435, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(28.9784, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7454, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2497):  18%|████████████▋                                                         | 10/55 [00:03<00:23,  1.95it/s]
Loss 0 tensor(0.7417, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.3736, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7421, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.7984, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7383, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(13.9611, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7450, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2577):  27%|███████████████████                                                   | 15/55 [00:06<00:17,  2.31it/s]
Loss 0 tensor(0.7499, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(19.5674, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7488, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.0427, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7584, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(19.0433, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7542, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(34.6773, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7534, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(21.2796, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7570, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2458):  38%|██████████████████████████▋                                           | 21/55 [00:08<00:11,  2.84it/s]
Loss 0 tensor(0.7505, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.1352, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7531, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(32.8844, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7523, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.3455, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7600, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.2889, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7493, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.5160, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7561, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.1997):  47%|█████████████████████████████████                                     | 26/55 [00:10<00:09,  2.91it/s]
Loss 0 tensor(0.7474, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.2266, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7447, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(17.1848, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7548, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.2225, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7499, device='cuda:0', grad_fn=<RsubBackward1>)


Training: (loss 0.2413):  64%|████████████████████████████████████████████▌                         | 35/55 [00:14<00:08,  2.49it/s]
Loss 0 tensor(0.7500, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(16.5377, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7616, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(36.1223, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7512, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(30.7103, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7514, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.3255, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7435, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(25.0745, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7495, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(20.6179, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7521, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.4049, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7453, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.7092, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7587, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.0851, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7505, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2262):  75%|████████████████████████████████████████████████████▏                 | 41/55 [00:16<00:04,  2.87it/s]
Loss 0 tensor(0.7604, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(19.6571, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7487, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.6360, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7586, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.5125, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7487, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.4147, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7574, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(14.1675, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7545, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2350):  85%|███████████████████████████████████████████████████████████▊          | 47/55 [00:18<00:02,  2.92it/s]
Loss 0 tensor(0.7601, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(22.1183, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7552, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(34.3814, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7464, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(34.6711, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7563, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(19.0849, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7526, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(31.4995, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7573, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2225):  96%|███████████████████████████████████████████████████████████████████▍  | 53/55 [00:20<00:00,  2.91it/s]
Loss 0 tensor(0.7570, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.7243, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7538, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(18.3256, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7612, device='cuda:0', grad_fn=<RsubBackward1>)






Validation: (loss 0.2783):  86%|██████████████████████████████████████████████████████████▎         | 12/14 [00:10<00:01,  1.03it/s]
Loss 0 tensor(0.7610, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(17.8907, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7560, device='cuda:0', grad_fn=<RsubBackward1>)

Training: (loss 0.2936):   5%|███▊                                                                   | 3/55 [00:00<00:17,  3.00it/s]
Loss 0 tensor(0.7479, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(38.6190, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7504, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(26.1729, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7507, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.2238, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7595, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(23.7350, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7520, device='cuda:0', grad_fn=<RsubBackward1>)
Loss 1 tensor(24.0833, device='cuda:0', grad_fn=<MaxBackward1>)
Loss 0 tensor(0.7568, device='cuda:0', grad_fn=<RsubBackward1>)
Traceback (most recent call last):
  File "main.py", line 111, in <module>
    init_and_train_model(args.verbose)
  File "main.py", line 79, in init_and_train_model
    DeepSeg.train_model()
  File "/root/research/deep-segmentation/segmentation/unet/segmentation.py", line 235, in train_model
    training_losses, validation_losses, lr_rates = trainer.run_trainer()
  File "/root/research/deep-segmentation/segmentation/unet/trainer.py", line 59, in run_trainer
    self._train()
  File "/root/research/deep-segmentation/segmentation/unet/trainer.py", line 101, in _train
    input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)
KeyboardInterrupt