Progress:   0%|                                                                                                                           | 0/90 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "main.py", line 132, in <module>
    init_and_train_model(args.verbose)
  File "main.py", line 81, in init_and_train_model
    DeepSeg.train_model()
  File "/root/research/deep-segmentation/segmentation/unet/segmentation.py", line 242, in train_model
    training_losses, validation_losses, lr_rates = trainer.run_trainer()
  File "/root/research/deep-segmentation/segmentation/unet/trainer.py", line 59, in run_trainer
    self._train()
  File "/root/research/deep-segmentation/segmentation/unet/trainer.py", line 103, in _train
    out = self.model(input)  # one forward pass
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/research/deep-segmentation/segmentation/unet/unet.py", line 386, in forward
    x = module(before_pool, x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/research/deep-segmentation/segmentation/unet/unet.py", line 281, in forward
    y = self.norm2(y)  # normalization 2
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/batchnorm.py", line 167, in forward
    return F.batch_norm(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py", line 2281, in batch_norm
    return torch.batch_norm(
RuntimeError: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 23.70 GiB total capacity; 20.14 GiB already allocated; 406.19 MiB free; 21.68 GiB reserved in total by PyTorch)